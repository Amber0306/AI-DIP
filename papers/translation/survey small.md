# 0. abstrct

在计算机视觉中，检测微小物体一直是一个困难且具有挑战性的问题。在本文中，我们从小物体或微小物体的角度提供了基于深度学习的检测方法的最新和全面的调查。我们的调查的特点是彻底和详尽的分析小或微小的物体检测

我们全面介绍了现有的30个关于小或微小物体的数据集，总结了基于不同应用场景的小或微小物体的不同定义，如行人检测、交通s i g n s检测、人脸检测、遥感目标检测和日常生活中的物体检测等。然后从超分辨率技术、基于上下文的信息、多尺度表示学习、锚机制、训练策略、数据扩充和基于损失函数的方案等七个方面系统综述了小目标检测技术。最后，深入分析了12个流行数据集上的小目标检测性能。在性能分析的基础上，讨论了未来可能的研究方向。我们希望这项调查可以为研究人员提供指导，以促进对小或微小物体检测的理解，并进一步促进对小或微小物体检测系统的研究。

# 1. introduction
目标检测是计算机视觉中的一项基本任务。当给定一幅图像时，目标检测旨在找到每个目标实例的位置和内容。从应用程序的角度来看，对象检测可以分为两种类型:通用对象检测和特定于域的检测。第一类的目的是在统一的框架下检测不同类型的视觉对象，而第二类的目的是特定应用场景下的检测，如人脸检测[1，2]，交通标志检测[3，4]，行人检测[5，6]，遥感目标检测[7–10]等。目标检测已经广泛应用于许多领域，例如机器人视觉、自动驾驶、智能交通监控、人机交互、基于内容的图像检索、无人机场景分析、消费电子和增强现实。

尽管在大规模检测基准中已经在大型和中型物体上取得了令人印象深刻的结果，但是在小型或微型物体上的性能远不能令人满意。如MS-COCO challenge1的检测排行榜所示，小物体的检测准确率远低于大物体。如今，由于分辨率低、外观信息不足、先验知识有限等原因，小物体或微小物体检测[5–9，11–26]已经成为一个极具挑战性的问题。本文主要介绍了近三年来基于深度学习的微小物体检测方法的主要进展。为了完整性和更好的可读性，还包括了一些其他相关的工作。

## 1.1. Comparison with Previous Reviews
如表1中所总结的，近年来已经发表了许多物体检测综述。这些包括通用对象检测[27–31]。邹等[28]和赵等[27]只是提出了小目标检测的未来发展方向。这些作品提供了一个全面的，系统的，彻底的调查。然而，他们关注的是一般大小的物体，而不是小的或微小的物体。同时，它们没有深入分析小的或微小的物体检测。除了这些一般的物体探测调查，还有一些关于小物体探测的近期评论[32–35]。Nguyen等人[32]主要关注深度学习的四个模型上的小对象性能评估，包括Fast R-CNN [36]，Faster R-CNN [37]，RetinaNet [38]，YOLOv3 [39]。他们还对这些模型的优势和局限性进行了深刻的评估。在我们之前的工作[33]中，我们从多尺度特征学习、数据增强、训练策略、基于上下文的检测和基于GAN的检测等五个方面全面回顾了现有的基于深度学习的小物体检测方法。此外，我们详细介绍了评价标准，并在MS-COCO [40]、PASCAL-VOC [41]、Caltech [42]、KITTI [43]和TT100K [44]五个数据集上分析了不同算法的实验结果。最后，我们指出了未来五个有前景的研究方向。Chen等人[34]调查了基于深度学习的小对象检测的四个支柱:多尺度表示、上下文信息、超分辨率和区域提议。然后，他们列出了一些小对象检测数据集，并在MS-COCO、PASCAL-VOC和TT100K三个数据集上报告了不同方法的性能。他们的调查还提供了六个可能的未来方向。刘等[35]总结了小目标检测的四个挑战:1)单个特征层不包含小目标的足够信息；2)小对象的有限上下文信息；3)小物体的类不平衡；4)小物体正面例子不足。然后，他们提出了相应的解决方案如下:1)结合多个特征地图；2)添加上下文信息3)平衡类别示例；4)增加足够数量的正面例子。他们还基于三个基准数据集比较了一些小对象检测方法的性能，如YOLOv3、Faster RCNN和SSD [45]。虽然这些综述主要集中在小目标的检测方法和性能评估上，但是它们仅仅涵盖了2020年以前的文献，并没有涉及到小目标的检测。此外，这些作品缺乏对小或微小物体的定义和数据集的系统和全面的总结。最后但并非最不重要的是，这些论文对于在不同数据集上的不同小目标检测方法的分析和比较不够彻底、全面和深入。

与这些之前的调查不同，我们提出了一个基于深度学习的方法的最新调查，该方法专注于检测小或微小的对象。我们的审查的特点是彻底和深入的分析小或微小物体的检测。全面介绍了现有的小目标检测数据集，并根据不同的应用场景总结了小目标和微小目标的不同定义。然后系统地综述了小目标检测技术。最后对小目标和微小目标的检测性能进行了深入的分析和讨论。

## 1.2. Our contributions
我们在本文中的贡献总结如下:1)从微小物体的角度提供基于深度学习的检测算法的最新综述

2)全面总结了30个关于小或微小物体的数据集，并根据不同的应用场景，如行人检测、交通标志检测、人脸检测、遥感目标检测、日常生活中的物体检测等，给出了小或微小物体的不同定义

3)从超分辨率技术、基于上下文的信息、多尺度表示学习、锚机制、训练策略、数据扩充和基于损失函数的方案等七个方面系统综述了小目标检测技术

4)深入分析DOTA [46]，UAVDT [47]，AI-TOD [48]，DIOR [49]，KITTI，TinyPerson [50]，TT100K，WIDER FACE [51]，PASCALVOC，MS-COCO，SOD [52]和USC-GRAD-STDdb [53]等12个数据集上的小或微小物体检测性能。在性能分析的基础上，讨论了未来可能的研究方向。

这些贡献共同带来了一个最新的，彻底的，详尽的调查，并区别于以往的审查工作显着。我们认为这篇论文是对小目标探测社区的及时补充。此外，我们希望这项调查将为研究人员提供新的灵感，以促进对小或微小物体检测的理解，并进一步促进对检测系统的研究。

论文的其余部分组织如下。在第2节中，我们将介绍小型或微型对象的数据集和定义。第三节对基于深度学习的小目标检测技术进行了综述，第四节进行了性能分析和讨论，第五节给出了本文的结论。

# 2. Datasets and definitions for small or tiny objects
在本节中，我们首先按时间顺序介绍一些关于小型或微型对象的流行数据集。然后根据不同的应用场景，总结出对小对象或小对象的不同定义。

## 2.1. Datasets about small or tiny objects

数据集在目标检测中起着至关重要的作用。它们不仅为数据驱动算法提供数据，而且能够在不同的目标检测算法之间进行比较。然而，对于小的或微小的物体，很少有被普遍接受的数据集。大多数研究人员不得不在自己构建的数据集或从MS-Coco、Wide Face等大型数据集中提取的数据集上评估他们的小目标或微小目标检测方法。表2按时间顺序总结了一些关于小目标或微目标的流行数据集。

## 2.2. Definitions for small or tiny objects

小物体或微小物体的定义是指阐明物体的尺度或大小有多小，或者它们在图像中占据了多少像素。有两种主要的方法来定义小对象。其一是相对规模。根据SPIE的定义，如果物体大小小于原始图像的0.12%，则视为小物体。Krishna和Jwahar[72]指出，如果一个物体只占据图像的一小部分(不到图像面积的1%)，那么它就被认为是小的。

也就是说，小物体的包围盒应该覆盖不到原始图像的1%。另一个是绝对大小，如MS-COCO数据集中定义的小于32×32像素的小对象，USC-GRAD-STDdb[53]中定义的16×16像素的小对象。为了便于深入了解小目标检测，研究人员根据不同的应用场景对小目标或微目标给出了不同的定义，如表3所示。

# 3. Techniques for small or tiny object detection
## 3.1. An overview of small/tiny object detection
如图1所示，我们总结了用于小或微小目标检测的技术。我们试图从两个角度来理解小/微小目标检测：定义和难度。小/小对象检测的定义指的是确定图像中是否存在来自给定类别的小/小对象的任何实例，并且如果存在，则返回每个小/小对象实例的空间位置和范围(例如，通过边界框)。简而言之，小微目标检测需要完成两个步骤：定位和分类。一方面，丰富的语义信息有利于小对象的分类。基于语义上下文的信息和CNN的深层特征涵盖了丰富的语义信息，这对小对象分类有很大的帮助。另一方面，丰富的空间细节对于小目标定位是至关重要的。CNN的浅层特征和超分辨率技术可以捕捉到更多的小目标细节，提高了小目标的定位精度。此外，基于空间上下文的信息和锚定机制也对小目标定位具有重要意义。

与大中型目标相比，小/微小目标更难被准确检测到。这是因为在小/微小目标检测中存在四个困难。首先，小/小物体分辨率低，特征不足。二是对象尺度跨度大，多尺度并存。第三，小/微小物体的例子很少。最后，小/小物体的类别不平衡。有六种方法可以解决上述四个困难，如图1所示。
- 具体地说，由于从小对象中提取的有效特征非常有限，因此非常有必要捕获更多的附加上下文信息作为小对象的补充。
- 多尺度表征学习不仅能为小目标提供更有效的信息，而且在一定程度上缓解了目标尺度跨度大的问题。
- 此外，还使用了训练策略来处理对象尺度问题。
- 锚定机制通过自适应地设置锚定比例和比例，帮助更多的锚点匹配小物体的地面真实情况，从而改善了稀缺的小/微小物体的例子。
- 数据扩充是另一种有效的策略，它不仅可以缓解小对象的样本不足，还可以改善小对象的类别失衡。
- 此外，损失函数的使用也有助于平衡小对象的类别。

最后但并非最不重要的一点是，图1还简要介绍了第2节中所示的小型或微型对象的数据集和定义。

## 3.2. Techniques for small or tiny object detection
在总结了上述微小目标检测技术的基础上，我们将从超分辨率技术、基于上下文的信息、多尺度表示学习、锚定机制、训练策略、数据增强和基于损失函数的方案等七个方面对微小目标检测技术进行分析。为了清楚地解释每个方面的小/微小目标检测技术，我们首先综合描述了每个方面中的现有方法。然后详细总结了各个方面的优缺点。

### 3.2.1. Super-resolution techniques
超分辨率技术旨在从相应的低分辨率特征中恢复出高分辨率。高分辨率图像可以应用于小/微小目标检测，因为它提供了关于原始场景的更精细的细节。生成性对抗网络(GAN)[74]可用于重建高分辨率图像。它在包含产生器和鉴别器的图像超分辨率方面取得了很大进展[75]。生成器产生超分辨率图像以愚弄鉴别器，而鉴别器试图区分通过生成器产生的真实图像和虚假图像。

据我们所知，Li等人[76]首次将GAN方法用于小/微小物体检测任务。提出的感知GAN模型通过生成小对象的超分辨表示来缩小小对象与大对象的表示差异，从而改进了小交通标志的检测。感知GAN的细节如图2所示。具体地说，它的生成器是一个深度残差网络，它以低层特征作为输入，捕捉更多细节以进行超分辨表示。该生成器利用多个残差块学习小对象和相似大对象之间的残差表示。它的鉴别器以大目标的特征和小目标的超分辨表示为输入，分为对抗分支和感知分支。对抗分支包含三个完全连接的层，然后是sigmoid，用于区分生成的小对象超分辨区域和类似的大对象感知分支包含两个完全连接的层，然后是两个输出兄弟层，分别用于边界盒回归和分类，以验证生成的超分辨表示的检测精度。

为了减轻下采样操作对小交通标志细节丢失的影响，Yang等人[77]提出了一种从粗到细的小目标检测方法。具体来说，首先从低分辨率图像中计算出一些粗略的感兴趣区域（ROI）。利用对象位置的先验知识指导ROI的生成。然后从高分辨率图像中重新计算小ROI的特征，并从生成ROI的特征映射中获得大ROI的特征。此外，Pang等人【78】在统一的框架下，通过联合分类子网和超分辨率子网，提出了一种用于小规模行人检测的JSC网络。超分辨率子网旨在探索大规模行人和小规模行人之间的关系，以便从大规模行人中恢复小规模行人的详细信息。基于HOG+LUV[79]和JCS网络，构造多层信道特征（MCF）[80]来训练检测器。最后，将多尺度表示与MCF相结合，进一步提高了检测性能。

除了小型交通标志和小型行人检测外，一些研究人员还关注小型或微型人脸检测。Bai等人[81]将多分支全卷积网络作为基线检测器来裁剪包含或不包含人脸的区域，并将其分别传递给生成器和鉴别器。该生成器经过训练，从低分辨率输入面重建出清晰的超分辨率面，其中包括上采样和细化模块。非人脸区域被视为负数据，用于训练鉴别器，该鉴别器包括两个完全连接的层，以区分真实图像或生成的超分辨率区域，并分别对人脸或非人脸进行分类。随后，Liu等人[82]提出了一种算法，通过使用GAN从模糊的小人脸直接生成清晰的高分辨率人脸。此外，设计了一个先验信息估计网络来提取人脸图像特征，并分别估计地标热图。通过将这两个网络结合起来，提出的端到端框架既可以提高人脸分辨率，又可以检测出微小的人脸。

Zhang等人【83】提出了一种新的多任务生成对抗网络，即MTGAN，专注于检测小人脸或常见小物体。该发生器是一个超分辨率网络，它将小模糊图像向上采样为小尺度图像，并恢复详细信息以实现更精确的检测。与生成器不同，鉴别器是一个多任务网络。它用真/假分数、对象类别分数和回归偏移量描述每个超分辨率图像修补程序。在训练过程中，鉴别器中的分类和回归损失被反向传播到生成器中，以使生成器获得更详细的信息，便于检测。此外，Noh等人[84]检查了现有的关于特征级超分辨率的小目标检测方法，发现通过使用高分辨率目标特征作为监控信号并匹配输入和目标特征的相对感受野，性能得到了显著提高。因此，他们提出了一种新的特征级超分辨率（SR）模型。作为一种基于GAN的模型，SR特征生成器在SR特征鉴别器的指导下，利用SR目标提取器的特征作为目标，学习生成高分辨率特征。在推理过程中，一个较大的建议直接传递给较大的预测值进行定位和分类，而一个较小的建议首先通过SR特征生成器进行超级解析，然后传递给较小的预测值。

Chen等人以日常生活中的小对象为研究对象，通过使用MS-COCO和SUN数据集的图像子集，构建了一个小对象数据集。Krishna和Jawahar【72】在【52】所示的超分辨率列车图像上训练CNN。区域提案网络中的提案通过超分辨率网络进行上采样和流化，然后对其进行分类。通过分析小目标检测所依赖的因素以及性能和效率之间的权衡，Liu等人[85]提出了一种高分辨率检测网络（HRDNet）。HRDNet的主要思想是采用浅主干处理高分辨率图像，而采用深主干处理低分辨率图像。文献[86]证明了利用微小而浅的网络从高分辨率图像中提取特征的优势。HRDNet不仅可以高分辨率地获取小目标的更多细节，还可以通过集成多深度、多尺度的深度网络来保证其有效性和效率。针对小目标包围盒预测的局限性，Gu等[87]设计了一种基于生成和判别学习（GDL）的检测框架。首先设计了一种重构发生器网络，用于重构锚箱预测中从低频到高频的映射。然后检测器模块从生成的结果中提取RoI，并实现RoI头来预测对象类别和细化边界框。为了引导重建图像与相应图像相关，使用鉴别器模块将生成的结果与原始图像区分开来。受超分辨率对目标检测的积极影响的启发，Ji等人[88]提出了一种可与检测网络结合以提高小目标检测性能的框架，其中低分辨率图像由GAN以无监督的方式进行超分辨率处理。超分辨率网络和检测网络联合训练。特别是，在训练期间，检测损失被反向传播到超分辨率网络中，以便于检测。为了加快基于特征金字塔的对象检测器的推理速度，Yang等人[89]提出了一种新的查询机制，即QueryDet。首先在低分辨率特征中预测可能存在小对象的位置（查询键），并在这些位置使用高分辨率特征构建稀疏特征图（查询值。最后，利用稀疏检测头输出检测到的盒子。该方案以级联方式应用，能够快速准确地检测小对象。

除了关注图像中的小对象外，一些研究人员还探索视频中的小对象检测。Bosquet等人[53]构建了一个视频小对象数据集USC GRAD STDdb。同时，他们引入了一个专注于检测小物体（16×16像素以下）的STDnet。STDnet的高性能依赖于一种新的早期视觉注意机制，即区域上下文网络（RCN），以选择最有希望的区域，同时丢弃其余的输入图像。仅处理特定区域允许STDnet在更深的层中保留高分辨率特征图，从而提供较低的内存开销和较高的帧速率。高分辨率特征图是提高此类小目标定位精度的关键。Bosquet等人在STDnet[53]的基础上，提出了一种时空神经网络，即STDnet-ST，以进一步改进小目标检测。STDnet-ST可以随着时间的推移检测小对象，并将一对排名靠前的区域与包含这些小对象的可能性最高的区域相关联，从而允许将小对象作为小结节跨时间链接。为了提供高质量的Tubelet并提高精度，它们还引入了一种策略来消除无利可图的对象链接。此外，Wang等人[55]构建了一个取自大学课堂视频记录的小对象数据集。然后，提出了一种新的基于图像超分辨率的检测方法，以提高小目标的检测速度和精度。具体来说，他们在输入端添加了一个特征纹理传输模块，以提高该端的图像分辨率，并去除图像中的噪声。为了减少网络参数的数目，采用密集块代替剩余块。颈部融合了SPPnet【92】和PANet【93】来完成多尺度特征融合，以充分利用图像中小物体的特征。通过在YOLOv4[94]损失函数部分添加前景和背景平衡损失函数，解决了图像背景和前景不平衡的问题。表4显示了超分辨率技术的优缺点。

### 3.2.2. Context-based information
由于小对象本身包含的信息有限，因此上下文线索在小对象检测中起着至关重要的作用。众所周知，视觉对象通常出现在特定的环境中，有时与其他相关对象共存。一个典型的例子是鸟类通常在天空中飞行。在深度学习盛行之前，Oliva和Torralba【95】证明了小对象的周围区域可以提供有用的上下文信息来帮助检测目标对象。尽管CNN已经从具有多个抽象层次的层次特征表示中隐式地学习了上下文信息，但在基于深度学习的小对象检测中，显式地探索上下文信息（小对象与其他对象或背景之间的关系）仍然有价值。接下来，详细描述了一些基于深度学习的上下文信息检测方法。

Hu等人[96]在寻找小脸的背景下探索了问题的三个方面：尺度不变性、图像分辨率和背景推理的作用。他们以一种大规模的方式利用大型本地上下文。也就是说，他们定义了利用大规模感受野的模板（其中99%的模板超出了感兴趣的对象）。同时，他们揭示了背景对于寻找低分辨率人脸最为有用。为此，Zhang等人[97]设计了一个聚合连接网络（ACNet），它包括两个重要部分：聚合连接模块和上下文模块。聚合连接模块可以减少图像缩放导致的特征消失。上下文模块可以在不添加额外参数的情况下充分利用丰富的上下文线索。为了解决硬人脸检测问题，Tang等人[98]提出了金字塔盒，这是一种新颖的上下文辅助单镜头人脸检测器。他们分别通过设计金字塔锚、引入低级FPN和构建上下文敏感结构三个方面提高了上下文信息的利用率。

金字塔锚可以通过半监督方法监督高级上下文特征学习。低层次FPN将足够的高层次上下文语义特征与低层次人脸特征相结合，使得金字塔箱能够在一次拍摄中预测所有尺度的人脸。上下文敏感结构可以增加预测网络的容量，提高最终输出的准确性

随后，Li等人【99】优化了金字塔箱中的各个方面【98】，以进一步提高微小人脸的检测性能，包括平衡数据锚采样、双金字塔锚和密集上下文模块。具体而言，平衡数据锚采样可以获得不同大小的面的更均匀采样。双金字塔锚通过引入渐进锚损失来促进特征学习。具有紧密连接的密集上下文模块不仅扩大了接受域，而且可以有效地传输信息。与上述方法不同，Xi等人[100]试图利用每幅图像中所有预测对象之间的语义相似性来推广当前的小脸检测器。为此，他们提出了一个新的框架，在度量学习策略中将语义相似度建模为成对约束，然后使用图切割技术利用语义相似度改进预测。后来，Xi等人[101]构建了一个成对约束来描述语义相似度，并基于区分学习和图切割技术开发了一个新的框架。在三个广泛使用的基准数据集上的实验结果表明了该方法的有效性。

为了同时考虑到日常生活中的小面孔和小物体，Leng等人【102】开发了新的内部-外部网络（IENet），该网络利用物体的外观和上下文信息进行鲁棒检测。针对小目标的特征提取、方案定位和分类，分别设计了三个定制模块：双向特征融合模块（Bi FFM）、上下文推理模块（CRM）和上下文特征增强模块（CFAM）。具体而言，Bi-FFM通过将CNN中更深层次的语义特征转移到更低层次，将更低层次的细节特征转移到更深层次来捕获对象的内部特征，这不仅利用了卷积特征的层次结构，而且通过上下文关系来促进其预测。CRM通过上下文推理提高区域建议的质量，上下文推理利用容易检测到的对象帮助理解困难的对象。CFAM学习通过CRM生成的区域建议之间的成对关系，并利用这种关系生成与区域建议关联的全局特征信息，以进行准确分类。Fang等人以日常生活中的小对象检测为重点，利用MS-COCO数据集的一个子集来构建小对象数据库，并提出了一种基于更快的R-CNN的更灵活的上下文信息集成方法。它们裁剪围绕提议区域的八个相应上下文区域，包括左上、中上、右上、左中、右中、左下、中下和右下。需要区分这八个上下文子窗口是否跨越要素图的边界。也就是说，它们将有效的上下文窗口添加到区域建议中，并且只添加分类信息，而不是包含分类和回归信息的完整信息。这样可以在一定程度上提高小目标检测的精度。Fu等人【103】提出了一种新的用于小对象检测的上下文推理方法，该方法对对象之间固有的语义和空间布局关系进行建模和推断。基于初始的区域特征，他们首先设计一个语义模块来建模稀疏的语义关系。此外，他们还设计了一个空间布局模块，根据位置和形状信息对稀疏空间布局关系进行建模。然后将二者输入到上下文推理模块中，对上下文信息进行整合，再与原始区域特征进行融合，进行回归和分类。实验结果表明，该方案能有效提高小目标检测的性能。与上述三种方案不同，Lim等人【104】提出了一种新的方法，该方法通过串联多尺度特征，利用来自不同层的额外特征作为上下文。此外，他们还介绍了一种带有注意机制的检测方法，该方法可以聚焦图像中的对象，并且可以包含来自目标层的上下文信息。后来，Yan等人【105】提出了一种称为LocalNet的单级检测器，该检测器更加关注详细的信息建模。LocalNet的目的是在早期阶段保留更详细的信息，以增强小对象的表示。此外，他们还设计了一个局部细节上下文模块，以增强检测层的语义，从而重新引入网络中丢失的细节，并在有限的感受野范围内利用局部上下文。

以遥感小目标检测为重点，Liu等人[106]构建了一个多分量融合网络（MCFN），以提高遥感图像中小目标检测的准确性。他们首先设计了一个双金字塔融合网络，该网络通过编码和解码操作将空间和语义线索紧密连接起来，以提取小对象的特征。然后采用相对区域建议网络，充分捕捉小对象样本和部分对象的特征。最后，在最终检测之前，他们向建议区域添加上下文信息，以获得对背景干扰的鲁棒性。特征间图和不同尺度的特征图对网络的贡献不同。为了进一步增强遥感图像中检测小对象的有效权重，Yang等人【107】开发了一个初始平行注意网络，即IPAN。它包含三个并行模块：多尺度注意模块、上下文注意模块和通道注意模块。语境注意模块将广泛的语境线索编码到局部特征中，从而增强表征能力。IPAN不仅可以提取丰富的多尺度、上下文特征和不同通道中全局特征的相互依赖性，而且可以基于注意机制提取对象对另一个对象的长期依赖性，这有助于小对象检测。与MCFN【106】和IPAN【107】不同，Liang等人【108】提出了一种基于特征融合和缩放的SSD（FS-SSD），用于无人机图像中的小目标检测。除了FSSSD学习到的深层特征外，还提出了空间上下文分析，通过将对象空间关系纳入到对象重新检测中，进一步提高检测精度。将不同对象实例之间的类间距离和类内距离作为空间上下文进行计算，这对于多类小对象的检测是有效的。随后，Cheng等人【109】设计了上下文特征增强模块，以利用全局上下文线索，并通过使用指示是否存在对象类的图像级上下文信息，有选择地增强类别软件特征。此外，它们还利用上下文编码丢失对模型训练进行正则化，从而促进对象检测器更好地理解场景，并缩小预测中可能的对象类别。

除了小人脸检测、日常生活中的小目标检测和遥感中的小目标检测之外，基于上下文的信息也被用于其他领域的小目标检测

Bosquet等人【73】开发了一个完全卷积的网络，专注于视频中的小目标。该网络包括一种早期视觉注意机制，称为区域上下文网络（RCN），用于选择具有一个或多个小对象及其上下文的最有希望的区域，并将其作为一组不相交的区域返回。过滤后的特征地图只包含最可能包含小对象的区域，通过网络转发到最终区域建议网络（RPN），该网络为最终分类阶段提供信息。RCN是通过更精细的空间分辨率提高定位精度的关键，因为它具有更精细的全局有效步长、更高的帧速率和更低的内存开销。CNN中的细粒度特征对于网络精确定位小的或部分遮挡的对象至关重要。为了缓解深层CNN难以为高级特征图提取足够的区分细粒度特征的问题，Guan等人【110】首先以自上而下的顺序构建更大、更有意义的特征图，并将其串联，然后通过金字塔池融合多级上下文信息，构建上下文感知特征。因此，实现了一个称为语义上下文感知网络（SCAN）的统一框架，以提高目标检测的准确性。Cui等人【111】通过构建高分辨率、强语义的特征地图，设计了一种上下文感知块网络（CABNet），以提高交通标志和小头等小对象的检测性能。为了在内部增强具有高空间分辨率的特征地图的表示能力，他们设计了上下文感知块（CAB），该块利用金字塔扩展卷积来合并多级上下文信息，而不会丢失特征地图的原始分辨率。然后，他们以相对较小的下采样因子将CAB组装到截断骨干网络的末端，并丢弃所有后续层。Hong等人以小人检测为重点，提出了一种尺度选择金字塔网络（SSPNet），该网络由三个模块组成，包括上下文注意模块（CAM）、尺度增强模块（SEM）和尺度选择模块（SSM）。CAM考虑上下文信息来生成层次化的注意热图。扫描电镜（SEM）突出了不同层面上特定尺度的特征，使探测器聚焦于特定尺度的物体，而不是广阔的背景。SSM利用相邻层之间的关系，在浅层和深层之间实现适当的特征共享，从而避免了不同层之间梯度计算的不一致性。在表5中，我们总结了上述基于上下文的方案的优缺点。

这些方法主要是通过学习对象与周围信息之间的关系来获取感兴趣区域周围的线索和改进对象分类。然而，并非所有基于上下文的信息都有助于检测。冗余的上下文信息还会导致信息噪音，从而影响小对象的性能。另一方面，这些方法没有考虑到场景中可能缺少上下文信息，也没有有针对性地利用场景中易于检测的结果来帮助检测小对象。

### 3.2.3. Multi-scale representation learning
多尺度表示学习也是一种有效的小目标检测策略。首先，我们简要展示了图3中的四种经典方法，包括特征化图像金字塔、单一特征映射、金字塔特征层次和特征金字塔网络

然后，详细介绍了基于它们的一些改进方法。

如图3（a）所示，以前的物体检测器通常采用特征化的图像金字塔来检测不同尺度的物体。即，他们将输入图像调整为许多不同的尺度，并学习多个检测器，每个检测器负责一定范围的尺度。随着深度学习的发展，Liu等人[113]提出了一种图像金字塔制导网络（IPGNet），以确保每一层都有丰富的空间和语义信息。它由两个主要模块组成：IPG转换和融合模块。即使在主干的最深阶段，IPG转换模块仍保留足够的空间信息，用于边界盒回归和分类。此外，IPG融合模块还融合了图像金字塔特征和主干特征。该方案的主要思想是在骨干网中引入IPG来处理信息不平衡问题，从而缓解小对象特征的消失。然而，由于内存消耗和推理时间的快速增加，这种方法的计算代价很高。Liu等人

【85】分析了小目标检测所依赖的因素以及效率和性能之间的权衡，并提出了一种高分辨率检测网络（HRDNet）。它包括一个重要的部分，即多深度图像金字塔网络（MD-IPN）。MD-IPN利用多个深度主干维护多个位置信息。通过从高分辨率到低分辨率提取各种特征，可以提高小目标检测性能，同时保持大中型目标的检测性能。为了减少这些特征之间的信息不平衡，还提出了一种多尺度特征金字塔网络来对齐和融合MD-IPN生成的多尺度特征组。HRDNet不仅可以在高分辨率下获取小对象的更多细节，还可以通过集成多深度、多尺度的网络来保证有效性和效率。

一些检测方案（如更快的R-CNN[37]和R-FCN[114]）使用CNN在单个输入尺度上计算的最顶层特征图来预测具有不同纵横比和尺度的候选边界框（见图3（b））。但是，由于连续下采样，最顶层上的小对象几乎没有信息。这可能会影响小对象的检测性能。为此，Liu等人[45]提出了一种名为SSD的单激发检测器，它可以从多层检测具有不同尺度和纵横比的对象。然后，从多个层进行预测，其中每个层负责一定比例的对象。实际上，深层CNN中的网络内特征层次结构生成了不同空间分辨率的特征图，同时引入了由不同深度引起的较大语义间隙（见图3（c））。也就是说，深层CNN学习不同层次的层次特征，从不同尺度的对象中获取信息。因此，SSD利用较浅层的特征检测较小的对象，而利用较深层的特征检测较大的对象。然后，提出了一些基于ssdbase的算法。

Cao等人[115]提出了一种在SSD中引入上下文线索的多级特征融合方法，即特征融合SSD（FFSSD）。此外，在融合阶段采用级联和元素和模块。为了进一步提高小目标的检测精度，Xu等人[116]提出了一种多尺度反卷积SSD，称为MDSSD。它们通过多尺度反褶积融合模块将具有语义信息的高层特征注入到底层特征中，得到信息丰富的特征图。特别是，它们在最顶层之前的多尺度特征上实现反褶积层，并将其与一些底层特征合并，以生成更多的语义特征图。此外，他们还添加了骨干网输出的conv3\u 3用于预测，以提高CNN对小目标的检测性能。与这两种架构不同，Sun等人【117】提出了一种掩模引导SSD，通过增强上下文信息的功能和引入分割掩模来消除背景区域，从而提高SSD检测小对象的性能。它由检测分支和分割分支组成。他们构建了一个特征融合模块，使检测分支能够利用上下文信息获得高分辨率的特征地图。分割分支主要通过扩展卷积来构建，为检测分支提供额外的上下文线索。此外，利用分割特征生成掩模，用于指导检测分支在潜在前景区域中找到目标。

受人类视觉系统中感受野（RFs）结构的启发，Liu等人【118】提出了一种新的RF块（RFB），该块考虑了RFs大小和偏心率之间的关系，以增强特征的可辨别性和鲁棒性。通过将RFB组装到SSD顶部，构建RFBNet检测器。RFBNet在保持实时速度的同时，可以达到高级甚深探测器的性能。与RFBNet类似，Li等人【119】开发了一种新的三叉戟网络（TridentNet），旨在生成具有统一表示力的特定比例特征地图。他们构建了一个平行的多分支结构，其中每个分支共享相同的参数，但具有不同的感受野。为了改进无人机捕获图像中小目标的检测，Razaak等人【120】提出了一种在SSD目标检测器上使用反卷积模块进行低级别特征组合的多尺度方法。后来，Han等人【121】引入D-RFB模块，可以增强特征图的表示能力。与D-RFB模块集成的D-RFBNet可以更准确地检测无人机图像中的小目标。

为了结合单一特征映射和金字塔特征层次之间的优势，Lin等人[122]提出了特征金字塔网络（FPN）。它构建了一个具有横向连接的自顶向下的体系结构，以生成一系列比例不变的特征映射，并在这些特征金字塔上学习多个与比例相关的分类器（见图3（d））具体而言，浅层空间丰富的特征通过深层语义丰富的特征得到加强。这些横向和自上而下的特征通过串联或元素求和进行集成。随后，提出了FPN的许多变体。与传统检测器相比，这些方法通过对特征金字塔块的一些修改，在检测精度上有了显著的提高。

为了弥补现有方法在检测遥感小目标方面的不足，Qu等人[123]提出了一种扩展卷积和特征融合检测器DFSSD。该检测器利用FPN的结构，将高分辨率的低层特征图与语义丰富的高层特征图进行融合。它还通过采用扩张卷积来提高DFSSD网络三级特征图的感受野。随后，Liang等人【108】提出了一种基于特征融合和缩放的SSD检测器，名为FS-SSD，用于无人机图像中的小目标检测。他们在反褶积模块中添加了一个额外的缩放分支，并使用平均池操作来形成一个特征金字塔。然后对原始特征融合分支进行调整，使其更好地适应小目标检测任务。最后，使用反褶积模块和特征融合模块生成的这两个特征金字塔一起进行预测。与DFSSD和FS-SSD不同，Liu等人【106】构建了一个多分量融合网络（MCFN），它包含三个主要部分：双金字塔融合网络（DPFN）、相对区域提议网络（RRPN）和上下文信息网络（CIN）。具体来说，DPFN通过编码和解码操作，将空间和语义信息紧密地连接起来，以提取小对象的特征。RRPN能够充分捕获小对象样本和部分对象的特征。CIN能够实现对背景干扰的鲁棒性。与多分量融合网络（MCFN）不同，Liu等人[124]构建了一个多分支并行特征金字塔网络（MPFPN），以提取无人机捕获图像中小尺寸物体更丰富的特征信息。并行分支旨在恢复深层中缺失的特征。为了减弱背景噪声推理和聚焦目标信息的影响，在MPFPN中引入了有监督的空间注意模块。此外，他们在快速R-CNN阶段使用级联架构，以获得更强大的定位能力。除了上述方法外，还有一些方法[54125]试图使用双向策略。Zheng等人[125]提出了一种双向阶梯串联特征金字塔方法。阶梯式拼接策略有助于避免金字塔构建过程中当前层的信息丢失，双向方案确保融合特征同时包含细节和语义信息。此外，还设计了注意交互模块，以更好地聚合双流功能，从而提高网络性能。同样，Li等人[54]提出了跨层注意网络（CANet）。他们首先设计了一个上采样和下采样特征金字塔，通过双向融合深度和浅层特征以及跳过连接来获得更丰富的上下文信息。然后，提出了一种跨层注意模块来捕获每层中小对象的非局部关联，并通过跨层集成和平衡进一步增强其表示能力。为了解决特征金字塔中自上而下的操作会导致不同层次的特征相互影响的问题，Cheng等人[126]提出了感知特征金字塔网络（AFPN）。AFPN学习特征金字塔中较高级别特征的向量，以获得清晰的特征。此外，通过使用新的组分配策略，可以更好地分配正负标签。

除了遥感图像中的小目标检测外，日常生活中的小目标检测也引起了研究人员的广泛关注。Liang等人【127】开发了一种名为深度特征金字塔网络（DFPN）的新型检测器。DFPN采用横向连接的特征金字塔结构，使小对象的语义特征更加敏感。此外，他们还设计了专门的锚来检测大分辨率图像中的小目标，然后训练具有焦点丢失的网络。为了缓解目标检测训练中样本水平、特征水平和目标水平的不平衡，Pang等人[128]提出了一个称为Libra R-CNN的有效框架，该框架分别集成了三个新组件：IoU平衡采样、平衡特征金字塔和平衡L1损失。得益于整体平衡设计，Libra R-CNN显著提高了小物体的检测性能。与这两种方法不同，Zheng等人[129]提出了一种交互式多尺度特征表示增强（IMFRE）策略，该策略包括两部分：多尺度辅助增强网络（MAEN）和自适应交互模块（AIM）。MAEN是针对多输入下的特征交互而提出的。它们将输入缩放到与预测层对应的多个尺度，只通过轻量级模块提取更详细的特征，以增强原始特征。AIM旨在聚合相邻层的特征。该方法在不改变原始网络结构的情况下，可以灵活地实现对小目标检测的改进。考虑到实时嵌入式设备上的小对象检测，Chen等人[130]提出了RHF网络，一种新型递归混合融合金字塔网络。所提出的RHFNet有两个新颖之处：即双向融合模块、递归级联和整形模块。前者可以融合自顶向下和自下而上方向的特征映射，生成灵活的特征金字塔，用于小目标检测。后者不仅可以递归地连接深层的高级语义特征，还可以重塑较浅层的空间丰富特征，以防止小对象消失。RHFNet在融合过程中采用了低计算成本和特征保持操作，因此在嵌入式设备上具有高效和准确的性能。

为了在广阔的视野和巨大的背景中检测微小的人，Liu等人【131】设计了一种特征重缩放和融合（SFRF）方法。通过设计一种非参数自适应稠密感知算法，该算法可以自动选择并生成具有高密度分布的微小物体的新尺寸特征地图。为了增强特征表示，他们还使用多对一策略对FPN层进行特征融合。Gong等人【132】认为FPN中相邻层之间自上而下的连接会对微小物体检测产生负面影响。他们引入了一种称为融合因子的新概念来控制从深层到浅层的信息传输，以使FPN适应微小目标检测。此外，他们还探讨了如何通过统计策略估计特定数据集的融合因子的有效值。经过一系列的实验和分析，他们发现估计值取决于分布在每一层中的对象数量。当使用适当的融合因子配置FPN时，网络可以在微小物体上实现显著的检测性能。虽然大多数现有的方法通过结合深层的上下文特征来丰富浅层的特征，但由于不同层之间梯度计算的不一致性的限制，FPN中的浅层没有被充分利用来检测微小对象。为此，Hong等人[112]提出了一种用于微小人物检测的尺度选择金字塔网络（SSPNet）。它由三个部分组成，包括上下文注意模块（CAM）、尺度增强模块（SEM）和尺度选择模块（SSM）。CAM考虑上下文信息来生成层次化的注意热图。扫描电镜（SEM）突出了不同层面上特定尺度的特征，使探测器聚焦于特定尺度的物体，而不是广阔的背景。SSM利用相邻层之间的关系，在浅层和深层之间实现适当的特征共享，从而避免了不同层之间梯度计算的不一致性。表6列出了上述多尺度表征学习方法的优缺点。

### 3.2.4. Anchor mechanism
在本节中，我们将讨论用于小对象检测的锚定机制。它主要分为锚定机构和无锚机构。

大多数现有检测器都广泛采用锚点 Faster R-CNN [37] 引入了区域提议网络（RPN）来生成提议。 RPN 基于锚点，锚点是预定义的不同大小和纵横比的区域，用于处理多个尺度。 RPN 生成边界框的坐标及其对应的类别，即对象和背景。最后，给定 RPN 的输出和特征提取器的最后一个特征图，目标的边界框和类别由全连接的分类网络确定。

后来，Dai 提出了一种基于区域的全卷积网络（R-FCN）来生成 k × k × (C + 1) 个特征图，而不是单个特征图，其中每个图负责每个类别的检测。然而，Faster RCNN 和 R-FCN 都不足以用于小目标检测，因为预定义锚的尺寸较大且全局有效步幅较粗。为此，Krishna 和 Jawahar [72] 在数学上找到了合适大小的锚框，并进行了详细的实验以揭示他们选择的有效性。通过引入预期最大重叠 (EMO) 分数，[133] 中的作者计算了锚点和对象之间的预期最大联合交集 (IoU)。他们发现锚 (SA) 的步幅越小，EMO 得分就越高，从统计学上讲，这会导致所有对象的平均最大 IoU 得到改善。值得注意的是，较小的 SA 可以采样更多高质量的样本，很好地捕捉小物体，这对检测器的训练和测试都有帮助。基于上述分析，Yang 等人。 [134] 设计了一个更精细的采样和特征融合网络（SFNet）。在基于anchor的检测框架中，SA的值等于特征图相对于原始图像的缩减因子 随后，Cascade R-CNN [135] 扩展了 Faster R-CNN 以解决过拟合和质量不匹配的问题。王等 [136]设计了一个级联掩码生成框架，该框架将多尺度图像作为输入，并按尺度升序处理它们。然后，每个尺度通过受 RoI 卷积启发的掩码生成模块生成区域提议和掩码。最后，将每个尺度的特征图连接起来用于 RoI 池化和后检测。

此外，锚定策略还用于小公司标识检测[137]、小规模行人检测[138]和小人脸检测[139-141]。Eggert等人。[137]推导出一个描述可合理建议的最小对象大小的关系，并提供一个启发式方法来为小公司标志选择合适的锚定尺度。张某等人。[138]提出了一种非对称多阶段网络(AMS-Net)，该网络在小规模行人检测中考虑了行人身体形状的不对称性。矩形锚被用来产生高度大于宽度的各种矩形方案。此外，采用非对称矩形卷积核函数来捕捉行人身体的紧凑特征。专注于小人脸检测，张等人。[139]提出了一种新的锚点加密策略，使不同类型的锚点在图像上具有相同的密度，显著提高了小人脸的召回率。后来，张等人提出了自己的观点。[140]在广泛的层上平铺锚点，以确保所有比例的脸都有足够的特征进行检测。基于有效感受野和等比例间隔原则，他们设计了锚定量表。通过尺度补偿锚点匹配策略提高了小人脸的召回率，并通过最大背景标签降低了小人脸的误检率。虽然基于锚点的人脸检测器取得了良好的性能，但它们对所有人脸一视同仁，忽略了简单人脸和难人脸之间的不平衡。张某等人。[141]开发了一种基于锚点的人脸检测器，它只输出单个带有小锚点的高分辨率特征图，专门学习小人脸，并通过一种新的硬图像挖掘方案来训练它，该方案根据图像上的困难程度自动调整图像上的训练权重。

为了追求高召回率，有必要在高分辨率特征地图上平铺大量密集锚点。然而，这导致了类别的极度不平衡，严重影响了检测框架中的分类任务。提出了一种自适应锚点平铺策略，如元锚点[142]和导向锚点[143]，以有效地缩小搜索空间。具体而言，Yang等人[142]提出了一种用于对象检测的称为元锚的新颖锚机制。与许多先前的检测器通过预定义的方式对锚进行建模不同，元锚中的锚函数可以从任意定制的先验盒中动态产生。通过这种方式，他们根据经验发现，MetaAnchor对锚点设置和边界框分布更加鲁棒。Wang等人[143]提出了一种称为引导锚定的方案，该方案使用语义特征来引导锚定。所提出的方法联合预测感兴趣对象的中心可能存在的位置以及不同位置处的比例和纵横比。在预测的锚形状之上，它们用特征适应模块减轻特征不一致性。这种锚定方法可以无缝地集成到提议方法和检测器中。为了执行更鲁棒的锚匹配，Duan等人[144]提出了一种新的基于锚的中心点平移的CPT匹配策略，以在训练阶段选择更多的扩展锚作为正样本。它们首先将多RPN的预测盒与IoU高于0.5的任何基本事实盒进行匹配，并标记它们相应的锚。然后，他们进一步基于表示锚和地面实况框之间的中心点距离与锚的比例的比率的阈值来选择更近的锚。同时，最负面的锚被移除。最后，他们将其余锚点的中心点转换到最近的地面实况框的中心。如果他们的借条高于门槛，就被认为是正面典型。这种策略有助于精确检测小物体。

除了基于锚的方法之外，一些研究人员放弃了先前的锚，他们利用无锚方法进行对象检测。Law等人[145]提出了一种用于对象检测的新方法CornerNet。他们使用单个CNN将对象边界框检测为成对的关键点，即左上角和右下角。他们还引入了角池来帮助网络更好地定位角。与CornerNet不同，Lu等人[146]引入了一种新的检测框架，称为网格R-CNN，它采用网格引导的定位机制进行精确的对象检测。他们不是只利用两个独立的点，而是设计一个多点监督公式来编码更多的线索，以减少特定点的不准确预测的影响。为了充分利用网格中点的相关性，他们提出了一种两阶段融合策略来融合相邻网格点的特征图。网格R-CNN可以实现高质量的目标定位。基于关键点的CornerNet在单级检测器中实现了高精度，但处理成本较高。Law等人[147]解决这个问题并引入CornerNet-Lite。CornerNetLite是基于CornerNet的两个变体的组合:CornerNetSaccade和CornerNet-Squeeze。通过结合这两种有效的变体，它在实时效率和高准确性之间取得了平衡.
在CornerNet的基础上，段等人[148]构建了一个称为CenterNet的框架。它将每个对象检测为一个三元组，而不是一对关键点，这提高了精确度和召回率。为此，他们设计了两个定制模块:级联角池和中心池。这些模块丰富了左上角和右下角捕获的信息，并从中心区域提供了更多可识别的信息。后来，周等人[149]利用标准的关键点估计网络来检测对象的四个极值点(最顶部、最左侧、最底部、最右侧)和一个中心点。所提出的ExtremeNet将五个关键点分组到一个边界框中，如果它们在几何上对齐的话。

与上述方法不同，周等人[150]将对象建模为单个点，即其包围盒的中心点。提出的检测器中心网采用关键点估计来寻找中心点，并回归到所有其他对象属性，如大小、位置和方向。后来，Wang等人[48]提出了一种称为MCenterNet的检测器，它使用多个中心点来定位精确的对象中心，以提高航空图像中微小对象检测的定位性能。Yang等人[151]提出了RepPoints(代表点)，这是一种新的更精细的对象表示，是一组对定位和识别都有用的样本点。给定用于训练的地面实况定位和识别目标，RepPoints学习以限制对象的空间范围并指示语义上重要的局部区域的方式自动排列它们自己。此外，他们不使用锚来采样包围盒的空间。与CenterNet [150]和RepPoints [151]不同，Tian等人[152]提出了一种全卷积一级检测器(FCOS)，用于以逐像素预测的方式进行目标检测。通过消除预定义的锚盒集，FCOS完全避免了与锚盒相关的复杂计算，例如在训练期间计算重叠。此外，它避免了关于锚盒的所有超参数，这些超参数通常对最终检测性能非常敏感。类似地，Kong等人[153]提出了用于对象检测的FoveaBox，它直接学习对象存在的可能性和包围盒坐标，而不需要锚参考。具体而言，通过预测对象存在可能性的类别敏感语义图，并为每个潜在包含对象的位置生成类别不可知的包围盒，来实现FoveaBox。此外，将一个实例分配给相邻的特征层，使模型更加精确。基于锚和无锚机制的优缺点如表7所示。

### 3.2.5. Training strategy
如今，基于深度CNN的对象检测器可以有利于多尺度训练和测试，其中图像被随机调整为不同的分辨率。虽然为大型物体训练探测器很简单，但关键的挑战仍然是为小型物体训练探测器。Hu等人[96]为不同的尺度训练单独的人脸检测器。为了保持效率，人脸检测器以多任务的方式进行训练:它们利用从多层单(深)特征层次中提取的特征。为了更好地检测小人脸，罗等人[154]提出了一种新颖的小人脸注意(SFA)检测器。具体来说，多分支人脸检测架构首先被设计为更关注小规模的人脸。然后，合并相邻分支的特征图，使得来自大尺度的特征可以辅助小尺度的硬脸检测。最后，他们同时使用多尺度训练和测试，使SFA对各种尺度都具有鲁棒性。因此，以这种方式学习的特征对于尺度变化更加鲁棒。多尺度训练策略不仅适用于小尺度人脸检测，也适用于微小物体的检测。高等[155]使用多尺度训练方法来提高微小目标检测的性能。具体而言，在PaddleDetection2中，短边的比例从832、896、960、1024、1088、1152、1216、1280、1344、1408、1472、1500中随机采样，而长边固定为2000。在MMDetection [156]中，短边的比例从480、528、576、624、672、720、768、816、912、960中随机采样，长边固定为1280。在训练过程中，NMS [157]面前的建议数从2000变为12000。在测试阶段，数据更改为6000。Feng等人[158]在训练时随机将输入图像缩放至原始大小的0.5、1、1.5倍，以帮助解决缩放差异问题。此外，考虑到TinyPerson中的对象非常小，基于多尺度训练策略，他们对训练图像进行上采样以获得更高的分辨率，从而获得更好的结果。然而，这种方法有其瓶颈。将训练图像上采样到更大的尺度有助于检测器提取更详细的特征，但同时会引入更多的失真。用1x训练计划实现的模型收敛不好，因此他们选择2x训练计划来训练模型，得到了更好的结果。上述训练策略在一定程度上有助于小人脸检测和微小物体检测。

为了在多尺度训练中标准化对象的尺度，Singh和Davis提出了一种新的训练策略，称为图像金字塔尺度标准化(SNIP) [159]，其选择性地反向传播不同尺寸的对象实例的梯度。在训练阶段，他们仅仅选择在特定分辨率下落在指定大小范围内的基本事实框和建议。类似地，在测试过程中，他们使用RPN为每个解决方案生成建议，并在每个解决方案中独立地对它们进行分类。同时，它们只选择在每个分辨率下的指定范围内的检测。后来，Singh等人提出了另一种有效的多尺度训练方法，即SNIPER [160]。它使用补丁作为训练数据，而不是常规图像。狙击手将地面真实情况周围的选定区域裁剪为阳性芯片，将样本背景裁剪为阴性芯片。它从多尺度图像金字塔中采样低分辨率区域，以加速多尺度训练。狙击和狙击可以有效提高小物体的探测性能。此外，Kim等人开发了一种称为SAN [161]的规模感知网络，并引入了一种新的学习方案，该方案仅考虑通道之间的关系，而不考虑空间信息。为了使基于CNN的检测器对尺度变化更加鲁棒，SAN将从不同尺度获得的卷积特征映射到尺度不变的子空间。它首先从尺度归一化面片提取卷积特征。然后利用提取的特征同时训练SAN和检测网络。与上述三种方法不同，周等人[162]提出了蒙太奇预训练，这是一种用于对象检测的通用预训练范式。与广泛使用的ImageNet预训练相比，蒙太奇预训练只需要目标检测数据集，而只占用四分之一的计算资源。具体来说，它们通过从原始图像中仔细提取有用的样本，以蒙太奇方式组合样本作为输入，并利用ERF-自适应密集分类方案进行模型预训练来减少潜在的冗余。这些设计在很大程度上考虑了网络利用率，提高了学习效率和最终性能。除了多尺度训练和蒙太奇预训练策略之外，Chen等人[163]引入了缩小图像的拼贴方式，并提出了动态尺度训练(DST)策略以减轻对象检测中的尺度变化挑战。他们利用来自优化过程的反馈信息来动态地指导数据准备。在每次训练迭代中，他们获取由于小物体造成的损失比例作为反馈。它可以在模型训练期间的每次正向传播之后被计算。所提出的策略是简单的，但获得了显著的好处，优于以前的方案。表8显示了上述培训策略的优点和缺点。

经过多尺度训练的模型可以通过匹配多尺度测试进一步提高检测性能

此外，蒙太奇预训练方案和动态尺度训练策略也有助于小或微小目标的检测。

虽然通过多尺度训练和测试的方式学习到的特征对尺度变化具有更强的鲁棒性，但它也会影响推理速度。例如，SNIP和SNIPER依赖于多尺度测试，存在推断负担

此外，它们在训练过程中以静态的方式操作，使它们无法提供网络所需的尺度敏感数据，从而忽略了动态的优点。

### 3.2.6. Data augmentation

数据是任何深度学习模型的核心。训练样本不足常常是深度学习问题解决方案表现不佳的原因。因此，使用大量数据进行训练对于任何深度学习模型的良好性能都是至关重要的[164]。数据扩充是一种技术，可用于通过人工产生数据集中现有实际图像的变化来扩展深度学习模型用于训练所需的数据集的大小。它可以大致分为四类:几何变换(例如，缩放、旋转、翻转、裁剪、填充等。)、颜色变换(例如改变图像中的对比度、亮度、色调、饱和度、噪声)、随机遮挡(例如随机剪切、擦除、隐藏和寻找、网格蒙版、剪切混合[165]和马赛克增强等。)和基于深度学习的方案。Gao等人[155]通过概率为0.5的随机水平翻转来增加训练数据。此外，他们还采取随机种植和扩大。类似地，周等人[162]对前景斑块进行裁剪，以构建拼图组合，用于上游分类。YOLOv4 [94]首次将镶嵌增强用于图像中的小物体检测。他们将四幅图像连接成一幅图像。因此，结合图像中的对象以比原始图像更小的比例出现。这种增强有助于改善图像中小目标的检测。几何变换、颜色变换和随机遮挡这三种增强并不总是捕捉环境中的所有差异。此外，还有可能丢失原始数据集的信息或特征，因为这些技术试图改变图像的几何形状或光照条件[164]。

如今，基于深度学习的数据增强方法提供了更有说服力的证据。与分类任务相比，为目标检测设计合理的增强方案更加困难。Zoph等人[166]试图采用自动增强[167]来为对象检测设计更好的数据增强策略。他们还采用这种策略来评估数据增强在目标检测中的价值，并将其与模型架构的价值进行比较。他们在不改变任何网络架构的情况下实现了最先进的技术。像[166，167]这样的定制扩充似乎在一定程度上缓解了变异问题。这些方法涉及到在实际重新训练之前优化策略控制器的数千个GPU日。此外，所搜索的策略在重新训练期间也是固定的，而不适应优化。为了解决以下两个问题:1)只有少数图像包含小对象2)小对象的位置缺乏多样性，Kisantal等人[168]分别提出了两个方案:1)他们通过对包含小对象的那些图像进行过采样来解决第一个问题2)他们通过在包含小对象的每个图像中多次复制粘贴小对象来解决第二个问题。这两种方法极大地改进了小物体的检测。然而，我们不能在无人机拍摄的图像中随机粘贴裁剪的对象。在无人机拍摄的图像中有一个明显的位置先验。例如，汽车在天上飞是不可能的。因此，Chen等人[169]引入了一种新的自适应数据扩充策略，称为自适应重采样(AdaResampling ),对数据进行逻辑扩充。

Tang等人[98]针对人脸检测，利用数据锚定采样(data-anchorsampling, DAS)方案在不同尺度上增加训练样本，这增加了较小人脸的训练数据多样性。简而言之，数据锚定采样调整训练图像的大小，通过重塑该图像中的随机人脸到一个随机较小的锚定大小。为了进一步提高人脸检测器的性能，Li等人[99]结合了原始ssd采样和数据锚定采样方案，其中颜色扭曲、随机裁剪和水平翻转以指定的概率值对照片进行处理。因此，他们引入了一种平衡数据锚定采样(BDAS)策略。它以等概率选取锚的尺寸，然后在锚尺寸附近的区间内也以等概率得到所选取的尺寸。在实现中，他们分别使用概率为0.8的BDAS和概率为0.2的ssd采样。

与上述方法不同，Chen等人[170]提出了一种新的反馈驱动数据提供者——Stitcher。在Stitcher中，图像被重新调整为更小的组件，然后再拼接成相同大小的常规图像。拼接后的图像中不可避免地包含较小的物体，利用损失统计作为反馈，有利于指导下一次迭代的更新。此外，还有一些方法[50,158,171]专门用于检测微小的人。Yu等人[50]提出了一种有效的尺度匹配(SM)策略。根据不同的物体大小对图像进行裁剪，缩小不同大小物体之间的差距，避免了传统缩放操作中容易丢失小物体信息的情况。Feng等人[158]开发了一套进一步提高探测器性能的策略，包括基于SM的数据增强，该策略将现有的大规模数据集和TinyPerson数据集之间的对象尺度进行校准。该策略可以获得良好的小目标表示。随后，Jiang等人[171]综合分析了TinyPerson的尺度信息，提出了一种新颖的精细尺度匹配方案，即SM +，用于微小人的检测。与只考虑整体形象的SM不同，SM+关注每一个实例。该方法有效地提高了预训练数据集与目标数据集之间的相似性，在很大程度上提高了检测性能。表9列出了数据增强方法的优缺点。

对于任何领域，获取大量的新图像都是一件非常麻烦的事情。从这个角度来看，数据增强方法可以节省时间和成本。此外，改变模型架构的代价是增加推理的复杂性，使模型变慢。然而，数据增强策略在这方面不会增加任何推理复杂性。

在目标检测中设计合理的增强策略比在分类中要困难得多

与网络结构的进步相比，数据增强方案的研究较少，这可能是因为数据增强方案在检测性能上的附加值较低，且传输性能较差。

### 3.2.7. Schemes based on loss function
优化损失函数是提高小目标检测性能的有效策略。深度CNN通常利用的损耗贡献主要来自于容易检测到的样本。交叉熵损失(CEL)函数对于一些硬样本的检测是不利的，比如小规模的行人。因此，Han等人[172]基于CEL设计了一种新的损失函数，以增加难以检测的例子的损失贡献。此外，Wu等人[173]采用了模拟损失函数，迫使小规模行人的特征表示接近大规模行人的特征表示。实验结果表明，采用模拟损失训练的检测器对于小尺度行人检测是有效的。

Chen等人[174]提出了一种新的框架，用排序任务代替单级检测器中的分类任务，并使用平均精度损失(AP损失)来解决排序问题。此外，他们提出了一种新的错误驱动学习算法，以有效地优化基于AP的目标函数。然而，AP损失集中在原始对上，不可微分。必须设计一种特定的方法来尽量减少ap损失。为此，Qian等人[175]开发了一种新的分布排序损失(DR loss)来应对这一挑战。DR损失对分布的期望进行排序，以取代原始对。此外，DR损失是可微的，并可以在标准训练管道中使用随机梯度下降(SGD)进行优化。上述两种基于损失函数的方案通过对损失函数中不平衡类别的实例进行加权来平衡前景实例和背景实例。与这两种方法不同，Lin等人[38]试图通过重塑标准CEL来处理类不平衡，从而降低分配给分类良好的示例的损失。提出的新焦点损失集中训练在一个稀疏的硬例子集，并防止大量容易的负面压倒检测器在训练期间。为了评估焦损的有效性，他们设计并训练了一个简单的密集检测器，即视网膜网络。随后，Zhang等[176]将级联思想应用到retina et中，提出了一种新的对象检测器CasRetinaNet，进一步提高了小目标检测的精度。为了进一步缓解样本不平衡问题对检测性能的负面影响，Ji等人[57]提出了一种新型ω-焦点损失函数，显著提高了对象较少类别的检测精度。通过将多尺度接收场注意力和ω-焦点损失集成到端到端架构中，他们开发了一个称为商品网(CommodityNet)的一级框架，用于小而密集的商品检测。受焦点损失的启发，Wang等[177]设计了一个焦点-区域损失函数，通过聚焦道路上石头等小物体的区域变化来学习。该损失函数可以提高小目标在分类损失中的重要性，从而促进道路上小目标的准确检测。

为了将焦点损失从离散形式推广到成功优化的连续形式，Li等人[178]提出了广义焦点损失(GFL)。将其分为质量焦损失(QFL)和分布焦损失(DFL)，分别对改进的两种表示方式进行优化。更具体地说，QFL关注硬例子的稀疏集，同时生成它们在相应类上的连续0 ~ 1质量估计。DFL使网络快速专注于学习对象包围盒连续位置周围值的概率，在任意和灵活的分布下。在GFL中引入了边界盒分布作为“一般分布”，较好地描述了预测边界盒的不确定性。与GFL不同，Li等人[179]探索了一种基于学习到的包围盒四个参数的分布来进行定位质量估计(LQE)的新视角。通过利用分布统计量与真实定位质量之间的密切相关性，他们引入了一种基于GFL的轻型分布引导质量预测器(DGQP)，从而构建了广义焦损v2 (GFLv2)。

基于损失函数的方法也有助于目标定位和加速检测。Yu等人[180]提出了一种用于包围盒预测的交集/联合损失(IoU损失)函数，该函数将预测框的四个边界回归为一个整体。通过利用IoU丢失和深度全卷积网络的优势，引入UnitBox，实现精确高效的定位，对各种形状和尺度的物体具有鲁棒性。随后，Tychsen-Smith等人[181]提出了有界借据损失，基于一组借据上界，提出了一种新的边界盒回归损失，该损失能更好地匹配借据最大化的目标，同时仍保持良好的收敛性。然而，IoU有一个平台，使其在不重叠边界框的情况下优化是不可行的。为此，Rezatofighi等人[182]通过开发一种广义版本的借据，将其作为一种新的损失和度量标准，对借据的弱点进行了分析。通过将这种广义IoU作为损失(GIoU损失)纳入现有检测器，他们在使用基于IoU和基于GIoU的检测基准上表现出了一致的性能改进。虽然IoU损失和GIoU损失已经被提出，但它们仍然存在收敛慢、回归不准确的问题。Zheng等人[183]提出了一种距离-IoU损失(DIoU损失)，通过合并预测框和目标框之间的归一化距离，在训练中收敛速度比IoU和GIoU损失快得多。

除上述方案外，还有一些基于损失函数的方法。He等[184]引入了一种新的边界框回归损失，即KL损失，用于同时学习边界框变换和局部化方差。这种损耗大大提高了各种体系结构的定位精度，几乎无需额外的计算。学习到的定位方差可以在非最大抑制过程中合并相邻的边界框，进一步提高小目标的定位性能。在CNN框架中，定位子网和分类子网之间的内在联系并没有被明确利用来进行目标检测。为此，Xu等人[185]提出了一种新的关联损失，即代理平方误差损失(PSE loss)，将两个子网相互交织，利用这两个子网获得的分类和定位分数之间的依赖关系来提高检测性能。通过对迭代中不同尺度上的损失分布的分析，小目标提供的损失与大目标提供的损失存在显著的差距.

为了平衡损失分布，缓解对小目标的监管不足，Liu等人[186]提出了一种新的反馈驱动的损失函数。与原有的损失函数相比，反馈驱动的损失函数可以更有效地监督小目标。它利用损耗分布信息作为反馈信号，以更均衡的方式训练模型。表10展示了基于损失函数的方案的优缺点。

# 4. Performance analysis and discussion
这一部分，我们评估了一些代表性的小或微小物体检测技术在12个流行的数据集上，按时间顺序，包括DOTA, UAVDT, AI-TOD, DIOR, KITTI, TinyPerson, TT100K, WIDER FACE, PASCAL-VOC, MS-COCO, SOD和usc - gradd - stddb

DOTA、UAVDT、AI-TOD和DIOR数据集用于遥感小目标检测。KITTI、TinyPerson、TT100K和WIDER FACE数据集分别用于行人检测、小人检测、交通标志检测和人脸检测。PASCALVOC、MS-COCO和SOD数据集用于日常生活中的小目标检测。USC-GRAD-STDdb数据库用于视频中的小目标检测

我们从7个方面对微小物体的检测方法进行了全面的总结。它们是超分辨率技术，基于上下文的信息，多尺度表示学习，锚定机制、训练策略、数据扩充及基于损失函数的方案。根据我们对小型或微小对象检测的分类，我们在表11中展示了对上述数据集的一些代表性方法的概述。在此基础上，基于性能分析对未来可能的研究方向进行了探讨。

##  4.1. Performance analysis
我们首先分别在表12和表13中报告了一些有代表性的方法对DOTA和UAVDT数据集的检测结果。显然，在DOTA数据集的15个类别上，SCRDet[134]的检测性能明显优于反馈驱动的损失[186]。在表13中，我们发现STDnet-ST[91]和RCN[73]分别对UAVDT的很小子集和UAVDT数据集的小子集的检测结果最好。

DIOR数据集上不同的小目标或微小目标检测算法的检测结果如表14所示。从表14可以看出，CANet[54]在DIOR数据集上获得了74.3%的mAP，优于其他5种方法。特别是在飞机、桥梁、烟囱、高速公路收费站、地面田径场、立交桥、船舶、体育场、储罐、网球场和车辆等大部分领域都取得了较好的成绩。此外，Cheng等[126]在机场、棒球场、篮球场、大坝、高速公路服务区、高尔夫球场、港口、火车站和风车等其他九个类别中也取得了较好的成绩。

不同探测器在AI-TOD数据集上的性能报告如表15所示。M-CenterNet[48]在AP、AP0.5、A Pvt、A Pt和oLRP五个指标中表现最佳。特别是在APvt和APt指标上，M-CenterNet远远超过了其他探测器。此外，如表16所示，M-CenterNet在桥梁、储罐、车辆、人、风车等5个类别上的性能最好。

表17和表18显示了不同方法在TinyPerson基准测试中MR和AP指标的性能。我们发现对于tiny1, tiny2和tiny3对象，Faster R-CNN with SFRF[131]在所有方法中效果最好。此外，这些检测器，即RetinaNet, Faster R-CNN和Cascade R-CNN，在使用SSPNet后得到了进一步的改进[112]。特别是Cascade R-CNN-SSPNet[112]和Faster R-CNN-SSPNet[112]分别获得了对小目标和微小目标的最佳检测性能。在表18中，F a s tr r - C N N SSPNet[112]在MR度量方面大大超过了其他方法。不难发现，采用多尺度表示学习和基于上下文信息的SSPNet可以很好地检测各种大小的对象，如tiny, tiny1~3和small object


我们比较了AMS-Net[138]、JCS-Net[78]、SqueezeDet[25]和SCAN[110]对KITTI挑战的检测结果。如表19所示，JCS-Net在中等水平和硬水平上优于AMS-Net。SCAN的“mAP”一栏比SqueezeDet表现出了显著的进步(1.6点)。具体来说，“Cyclists”这一栏的性能要比SqueezeDet要好得多，而“Cyclists- moderate”这一栏的得分要比SqueezeDet高出15.4分。

同样，我们在TT100K数据集上比较了Feature SR[84]、DFPN[127]、CasMaskGF[136]和Perceptual GAN[76]这四种方法。从表20中，我们可以观察到Feature SR在这四种方法中在Overall-F1方面提供了实质性的改进。更具体地说，“Small-F1”、“Medium-F1”和“Large-F1”列显示了相对于PerceptualGAN的显著收益(分别为2.2、2.6和5.5点)。CasMaskGF“Medium-F1”柱的F1值在4种方法中最高，为96.9%。此外，在三种目标尺寸中，小目标的检测性能最低。我们也在表21中列出最常用的交通标志的AP。与其他四种算法相比，D F P N在大多数分类中都取得了优异的性能。有些类别AP达到98%，如“il60”、“p27”、“pl100”、“pl70”和“pm20”。其中，“pl120”类AP最高，达99%。
# 5. Conclusion
本文全面讨论了小对象或微小对象数据集、小对象或微小对象的定义、小对象或微小对象检测技术、小对象或微小对象检测性能分析以及小对象检测的发展方向。这项工作为小对象检测社区带来了最新和彻底的调查。同时，我们希望这篇综述能够为研究人员进一步研究小目标检测系统提供指导。
