# 0. abstrct

在计算机视觉中，检测微小物体一直是一个困难且具有挑战性的问题。在本文中，我们从小物体或微小物体的角度提供了基于深度学习的检测方法的最新和全面的调查。我们的调查的特点是彻底和详尽的分析小或微小的物体检测

我们全面介绍了现有的30个关于小或微小物体的数据集，总结了基于不同应用场景的小或微小物体的不同定义，如行人检测、交通s i g n s检测、人脸检测、遥感目标检测和日常生活中的物体检测等。然后从超分辨率技术、基于上下文的信息、多尺度表示学习、锚机制、训练策略、数据扩充和基于损失函数的方案等七个方面系统综述了小目标检测技术。最后，深入分析了12个流行数据集上的小目标检测性能。在性能分析的基础上，讨论了未来可能的研究方向。我们希望这项调查可以为研究人员提供指导，以促进对小或微小物体检测的理解，并进一步促进对小或微小物体检测系统的研究。

# 1. introduction
目标检测是计算机视觉中的一项基本任务。当给定一幅图像时，目标检测旨在找到每个目标实例的位置和内容。从应用程序的角度来看，对象检测可以分为两种类型:通用对象检测和特定于域的检测。第一类的目的是在统一的框架下检测不同类型的视觉对象，而第二类的目的是特定应用场景下的检测，如人脸检测[1，2]，交通标志检测[3，4]，行人检测[5，6]，遥感目标检测[7–10]等。目标检测已经广泛应用于许多领域，例如机器人视觉、自动驾驶、智能交通监控、人机交互、基于内容的图像检索、无人机场景分析、消费电子和增强现实。

尽管在大规模检测基准中已经在大型和中型物体上取得了令人印象深刻的结果，但是在小型或微型物体上的性能远不能令人满意。如MS-COCO challenge1的检测排行榜所示，小物体的检测准确率远低于大物体。如今，由于分辨率低、外观信息不足、先验知识有限等原因，小物体或微小物体检测[5–9，11–26]已经成为一个极具挑战性的问题。本文主要介绍了近三年来基于深度学习的微小物体检测方法的主要进展。为了完整性和更好的可读性，还包括了一些其他相关的工作。

## 1.1. Comparison with Previous Reviews
如表1中所总结的，近年来已经发表了许多物体检测综述。这些包括通用对象检测[27–31]。邹等[28]和赵等[27]只是提出了小目标检测的未来发展方向。这些作品提供了一个全面的，系统的，彻底的调查。然而，他们关注的是一般大小的物体，而不是小的或微小的物体。同时，它们没有深入分析小的或微小的物体检测。除了这些一般的物体探测调查，还有一些关于小物体探测的近期评论[32–35]。Nguyen等人[32]主要关注深度学习的四个模型上的小对象性能评估，包括Fast R-CNN [36]，Faster R-CNN [37]，RetinaNet [38]，YOLOv3 [39]。他们还对这些模型的优势和局限性进行了深刻的评估。在我们之前的工作[33]中，我们从多尺度特征学习、数据增强、训练策略、基于上下文的检测和基于GAN的检测等五个方面全面回顾了现有的基于深度学习的小物体检测方法。此外，我们详细介绍了评价标准，并在MS-COCO [40]、PASCAL-VOC [41]、Caltech [42]、KITTI [43]和TT100K [44]五个数据集上分析了不同算法的实验结果。最后，我们指出了未来五个有前景的研究方向。Chen等人[34]调查了基于深度学习的小对象检测的四个支柱:多尺度表示、上下文信息、超分辨率和区域提议。然后，他们列出了一些小对象检测数据集，并在MS-COCO、PASCAL-VOC和TT100K三个数据集上报告了不同方法的性能。他们的调查还提供了六个可能的未来方向。刘等[35]总结了小目标检测的四个挑战:1)单个特征层不包含小目标的足够信息；2)小对象的有限上下文信息；3)小物体的类不平衡；4)小物体正面例子不足。然后，他们提出了相应的解决方案如下:1)结合多个特征地图；2)添加上下文信息3)平衡类别示例；4)增加足够数量的正面例子。他们还基于三个基准数据集比较了一些小对象检测方法的性能，如YOLOv3、Faster RCNN和SSD [45]。虽然这些综述主要集中在小目标的检测方法和性能评估上，但是它们仅仅涵盖了2020年以前的文献，并没有涉及到小目标的检测。此外，这些作品缺乏对小或微小物体的定义和数据集的系统和全面的总结。最后但并非最不重要的是，这些论文对于在不同数据集上的不同小目标检测方法的分析和比较不够彻底、全面和深入。

与这些之前的调查不同，我们提出了一个基于深度学习的方法的最新调查，该方法专注于检测小或微小的对象。我们的审查的特点是彻底和深入的分析小或微小物体的检测。全面介绍了现有的小目标检测数据集，并根据不同的应用场景总结了小目标和微小目标的不同定义。然后系统地综述了小目标检测技术。最后对小目标和微小目标的检测性能进行了深入的分析和讨论。

## 1.2. Our contributions
我们在本文中的贡献总结如下:1)从微小物体的角度提供基于深度学习的检测算法的最新综述

2)全面总结了30个关于小或微小物体的数据集，并根据不同的应用场景，如行人检测、交通标志检测、人脸检测、遥感目标检测、日常生活中的物体检测等，给出了小或微小物体的不同定义

3)从超分辨率技术、基于上下文的信息、多尺度表示学习、锚机制、训练策略、数据扩充和基于损失函数的方案等七个方面系统综述了小目标检测技术

4)深入分析DOTA [46]，UAVDT [47]，AI-TOD [48]，DIOR [49]，KITTI，TinyPerson [50]，TT100K，WIDER FACE [51]，PASCALVOC，MS-COCO，SOD [52]和USC-GRAD-STDdb [53]等12个数据集上的小或微小物体检测性能。在性能分析的基础上，讨论了未来可能的研究方向。

这些贡献共同带来了一个最新的，彻底的，详尽的调查，并区别于以往的审查工作显着。我们认为这篇论文是对小目标探测社区的及时补充。此外，我们希望这项调查将为研究人员提供新的灵感，以促进对小或微小物体检测的理解，并进一步促进对检测系统的研究。

论文的其余部分组织如下。在第2节中，我们将介绍小型或微型对象的数据集和定义。第三节对基于深度学习的小目标检测技术进行了综述，第四节进行了性能分析和讨论，第五节给出了本文的结论。

# 2. Datasets and definitions for small or tiny objects
在本节中，我们首先按时间顺序介绍一些关于小型或微型对象的流行数据集。然后根据不同的应用场景，总结出对小对象或小对象的不同定义。

## 2.1. Datasets about small or tiny objects

数据集在目标检测中起着至关重要的作用。它们不仅为数据驱动算法提供数据，而且能够在不同的目标检测算法之间进行比较。然而，对于小的或微小的物体，很少有被普遍接受的数据集。大多数研究人员不得不在自己构建的数据集或从MS-Coco、Wide Face等大型数据集中提取的数据集上评估他们的小目标或微小目标检测方法。表2按时间顺序总结了一些关于小目标或微目标的流行数据集。

## 2.2. Definitions for small or tiny objects

小物体或微小物体的定义是指阐明物体的尺度或大小有多小，或者它们在图像中占据了多少像素。有两种主要的方法来定义小对象。其一是相对规模。根据SPIE的定义，如果物体大小小于原始图像的0.12%，则视为小物体。Krishna和Jwahar[72]指出，如果一个物体只占据图像的一小部分(不到图像面积的1%)，那么它就被认为是小的。

也就是说，小物体的包围盒应该覆盖不到原始图像的1%。另一个是绝对大小，如MS-COCO数据集中定义的小于32×32像素的小对象，USC-GRAD-STDdb[53]中定义的16×16像素的小对象。为了便于深入了解小目标检测，研究人员根据不同的应用场景对小目标或微目标给出了不同的定义，如表3所示。

# 3. Techniques for small or tiny object detection
## 3.1. An overview of small/tiny object detection
如图1所示，我们总结了用于小或微小目标检测的技术。我们试图从两个角度来理解小/微小目标检测：定义和难度。小/小对象检测的定义指的是确定图像中是否存在来自给定类别的小/小对象的任何实例，并且如果存在，则返回每个小/小对象实例的空间位置和范围(例如，通过边界框)。简而言之，小微目标检测需要完成两个步骤：定位和分类。一方面，丰富的语义信息有利于小对象的分类。基于语义上下文的信息和CNN的深层特征涵盖了丰富的语义信息，这对小对象分类有很大的帮助。另一方面，丰富的空间细节对于小目标定位是至关重要的。CNN的浅层特征和超分辨率技术可以捕捉到更多的小目标细节，提高了小目标的定位精度。此外，基于空间上下文的信息和锚定机制也对小目标定位具有重要意义。

与大中型目标相比，小/微小目标更难被准确检测到。这是因为在小/微小目标检测中存在四个困难。首先，小/小物体分辨率低，特征不足。二是对象尺度跨度大，多尺度并存。第三，小/微小物体的例子很少。最后，小/小物体的类别不平衡。有六种方法可以解决上述四个困难，如图1所示。
- 具体地说，由于从小对象中提取的有效特征非常有限，因此非常有必要捕获更多的附加上下文信息作为小对象的补充。
- 多尺度表征学习不仅能为小目标提供更有效的信息，而且在一定程度上缓解了目标尺度跨度大的问题。
- 此外，还使用了训练策略来处理对象尺度问题。
- 锚定机制通过自适应地设置锚定比例和比例，帮助更多的锚点匹配小物体的地面真实情况，从而改善了稀缺的小/微小物体的例子。
- 数据扩充是另一种有效的策略，它不仅可以缓解小对象的样本不足，还可以改善小对象的类别失衡。
- 此外，损失函数的使用也有助于平衡小对象的类别。

最后但并非最不重要的一点是，图1还简要介绍了第2节中所示的小型或微型对象的数据集和定义。

## 3.2. Techniques for small or tiny object detection
在总结了上述微小目标检测技术的基础上，我们将从超分辨率技术、基于上下文的信息、多尺度表示学习、锚定机制、训练策略、数据增强和基于损失函数的方案等七个方面对微小目标检测技术进行分析。为了清楚地解释每个方面的小/微小目标检测技术，我们首先综合描述了每个方面中的现有方法。然后详细总结了各个方面的优缺点。

### 3.2.1. Super-resolution techniques
超分辨率技术旨在从相应的低分辨率特征中恢复出高分辨率。高分辨率图像可以应用于小/微小目标检测，因为它提供了关于原始场景的更精细的细节。生成性对抗网络(GAN)[74]可用于重建高分辨率图像。它在包含产生器和鉴别器的图像超分辨率方面取得了很大进展[75]。生成器产生超分辨率图像以愚弄鉴别器，而鉴别器试图区分通过生成器产生的真实图像和虚假图像。

据我们所知，Li等人[76]首次将GAN方法用于小/微小物体检测任务。提出的感知GAN模型通过生成小对象的超分辨表示来缩小小对象与大对象的表示差异，从而改进了小交通标志的检测。感知GAN的细节如图2所示。具体地说，它的生成器是一个深度残差网络，它以低层特征作为输入，捕捉更多细节以进行超分辨表示。该生成器利用多个残差块学习小对象和相似大对象之间的残差表示。它的鉴别器以大目标的特征和小目标的超分辨表示为输入，分为对抗分支和感知分支。对抗分支包含三个完全连接的层，然后是sigmoid，用于区分生成的小对象超分辨区域和类似的大对象感知分支包含两个完全连接的层，然后是两个输出兄弟层，分别用于边界盒回归和分类，以验证生成的超分辨表示的检测精度。

为了减轻下采样操作对小交通标志细节丢失的影响，Yang等人[77]提出了一种从粗到细的小目标检测方法。具体来说，首先从低分辨率图像中计算出一些粗略的感兴趣区域（ROI）。利用对象位置的先验知识指导ROI的生成。然后从高分辨率图像中重新计算小ROI的特征，并从生成ROI的特征映射中获得大ROI的特征。此外，Pang等人【78】在统一的框架下，通过联合分类子网和超分辨率子网，提出了一种用于小规模行人检测的JSC网络。超分辨率子网旨在探索大规模行人和小规模行人之间的关系，以便从大规模行人中恢复小规模行人的详细信息。基于HOG+LUV[79]和JCS网络，构造多层信道特征（MCF）[80]来训练检测器。最后，将多尺度表示与MCF相结合，进一步提高了检测性能。

除了小型交通标志和小型行人检测外，一些研究人员还关注小型或微型人脸检测。Bai等人[81]将多分支全卷积网络作为基线检测器来裁剪包含或不包含人脸的区域，并将其分别传递给生成器和鉴别器。该生成器经过训练，从低分辨率输入面重建出清晰的超分辨率面，其中包括上采样和细化模块。非人脸区域被视为负数据，用于训练鉴别器，该鉴别器包括两个完全连接的层，以区分真实图像或生成的超分辨率区域，并分别对人脸或非人脸进行分类。随后，Liu等人[82]提出了一种算法，通过使用GAN从模糊的小人脸直接生成清晰的高分辨率人脸。此外，设计了一个先验信息估计网络来提取人脸图像特征，并分别估计地标热图。通过将这两个网络结合起来，提出的端到端框架既可以提高人脸分辨率，又可以检测出微小的人脸。

Zhang等人【83】提出了一种新的多任务生成对抗网络，即MTGAN，专注于检测小人脸或常见小物体。该发生器是一个超分辨率网络，它将小模糊图像向上采样为小尺度图像，并恢复详细信息以实现更精确的检测。与生成器不同，鉴别器是一个多任务网络。它用真/假分数、对象类别分数和回归偏移量描述每个超分辨率图像修补程序。在训练过程中，鉴别器中的分类和回归损失被反向传播到生成器中，以使生成器获得更详细的信息，便于检测。此外，Noh等人[84]检查了现有的关于特征级超分辨率的小目标检测方法，发现通过使用高分辨率目标特征作为监控信号并匹配输入和目标特征的相对感受野，性能得到了显著提高。因此，他们提出了一种新的特征级超分辨率（SR）模型。作为一种基于GAN的模型，SR特征生成器在SR特征鉴别器的指导下，利用SR目标提取器的特征作为目标，学习生成高分辨率特征。在推理过程中，一个较大的建议直接传递给较大的预测值进行定位和分类，而一个较小的建议首先通过SR特征生成器进行超级解析，然后传递给较小的预测值。

Chen等人以日常生活中的小对象为研究对象，通过使用MS-COCO和SUN数据集的图像子集，构建了一个小对象数据集。Krishna和Jawahar【72】在【52】所示的超分辨率列车图像上训练CNN。区域提案网络中的提案通过超分辨率网络进行上采样和流化，然后对其进行分类。通过分析小目标检测所依赖的因素以及性能和效率之间的权衡，Liu等人[85]提出了一种高分辨率检测网络（HRDNet）。HRDNet的主要思想是采用浅主干处理高分辨率图像，而采用深主干处理低分辨率图像。文献[86]证明了利用微小而浅的网络从高分辨率图像中提取特征的优势。HRDNet不仅可以高分辨率地获取小目标的更多细节，还可以通过集成多深度、多尺度的深度网络来保证其有效性和效率。针对小目标包围盒预测的局限性，Gu等[87]设计了一种基于生成和判别学习（GDL）的检测框架。首先设计了一种重构发生器网络，用于重构锚箱预测中从低频到高频的映射。然后检测器模块从生成的结果中提取RoI，并实现RoI头来预测对象类别和细化边界框。为了引导重建图像与相应图像相关，使用鉴别器模块将生成的结果与原始图像区分开来。受超分辨率对目标检测的积极影响的启发，Ji等人[88]提出了一种可与检测网络结合以提高小目标检测性能的框架，其中低分辨率图像由GAN以无监督的方式进行超分辨率处理。超分辨率网络和检测网络联合训练。特别是，在训练期间，检测损失被反向传播到超分辨率网络中，以便于检测。为了加快基于特征金字塔的对象检测器的推理速度，Yang等人[89]提出了一种新的查询机制，即QueryDet。首先在低分辨率特征中预测可能存在小对象的位置（查询键），并在这些位置使用高分辨率特征构建稀疏特征图（查询值。最后，利用稀疏检测头输出检测到的盒子。该方案以级联方式应用，能够快速准确地检测小对象。

除了关注图像中的小对象外，一些研究人员还探索视频中的小对象检测。Bosquet等人[53]构建了一个视频小对象数据集USC GRAD STDdb。同时，他们引入了一个专注于检测小物体（16×16像素以下）的STDnet。STDnet的高性能依赖于一种新的早期视觉注意机制，即区域上下文网络（RCN），以选择最有希望的区域，同时丢弃其余的输入图像。仅处理特定区域允许STDnet在更深的层中保留高分辨率特征图，从而提供较低的内存开销和较高的帧速率。高分辨率特征图是提高此类小目标定位精度的关键。Bosquet等人在STDnet[53]的基础上，提出了一种时空神经网络，即STDnet-ST，以进一步改进小目标检测。STDnet-ST可以随着时间的推移检测小对象，并将一对排名靠前的区域与包含这些小对象的可能性最高的区域相关联，从而允许将小对象作为小结节跨时间链接。为了提供高质量的Tubelet并提高精度，它们还引入了一种策略来消除无利可图的对象链接。此外，Wang等人[55]构建了一个取自大学课堂视频记录的小对象数据集。然后，提出了一种新的基于图像超分辨率的检测方法，以提高小目标的检测速度和精度。具体来说，他们在输入端添加了一个特征纹理传输模块，以提高该端的图像分辨率，并去除图像中的噪声。为了减少网络参数的数目，采用密集块代替剩余块。颈部融合了SPPnet【92】和PANet【93】来完成多尺度特征融合，以充分利用图像中小物体的特征。通过在YOLOv4[94]损失函数部分添加前景和背景平衡损失函数，解决了图像背景和前景不平衡的问题。表4显示了超分辨率技术的优缺点。

### 3.2.2. Context-based information
由于小对象本身包含的信息有限，因此上下文线索在小对象检测中起着至关重要的作用。众所周知，视觉对象通常出现在特定的环境中，有时与其他相关对象共存。一个典型的例子是鸟类通常在天空中飞行。在深度学习盛行之前，Oliva和Torralba【95】证明了小对象的周围区域可以提供有用的上下文信息来帮助检测目标对象。尽管CNN已经从具有多个抽象层次的层次特征表示中隐式地学习了上下文信息，但在基于深度学习的小对象检测中，显式地探索上下文信息（小对象与其他对象或背景之间的关系）仍然有价值。接下来，详细描述了一些基于深度学习的上下文信息检测方法。

Hu等人[96]在寻找小脸的背景下探索了问题的三个方面：尺度不变性、图像分辨率和背景推理的作用。他们以一种大规模的方式利用大型本地上下文。也就是说，他们定义了利用大规模感受野的模板（其中99%的模板超出了感兴趣的对象）。同时，他们揭示了背景对于寻找低分辨率人脸最为有用。为此，Zhang等人[97]设计了一个聚合连接网络（ACNet），它包括两个重要部分：聚合连接模块和上下文模块。聚合连接模块可以减少图像缩放导致的特征消失。上下文模块可以在不添加额外参数的情况下充分利用丰富的上下文线索。为了解决硬人脸检测问题，Tang等人[98]提出了金字塔盒，这是一种新颖的上下文辅助单镜头人脸检测器。他们分别通过设计金字塔锚、引入低级FPN和构建上下文敏感结构三个方面提高了上下文信息的利用率。

金字塔锚可以通过半监督方法监督高级上下文特征学习。低层次FPN将足够的高层次上下文语义特征与低层次人脸特征相结合，使得金字塔箱能够在一次拍摄中预测所有尺度的人脸。上下文敏感结构可以增加预测网络的容量，提高最终输出的准确性

随后，Li等人【99】优化了金字塔箱中的各个方面【98】，以进一步提高微小人脸的检测性能，包括平衡数据锚采样、双金字塔锚和密集上下文模块。具体而言，平衡数据锚采样可以获得不同大小的面的更均匀采样。双金字塔锚通过引入渐进锚损失来促进特征学习。具有紧密连接的密集上下文模块不仅扩大了接受域，而且可以有效地传输信息。与上述方法不同，Xi等人[100]试图利用每幅图像中所有预测对象之间的语义相似性来推广当前的小脸检测器。为此，他们提出了一个新的框架，在度量学习策略中将语义相似度建模为成对约束，然后使用图切割技术利用语义相似度改进预测。后来，Xi等人[101]构建了一个成对约束来描述语义相似度，并基于区分学习和图切割技术开发了一个新的框架。在三个广泛使用的基准数据集上的实验结果表明了该方法的有效性。

为了同时考虑到日常生活中的小面孔和小物体，Leng等人【102】开发了新的内部-外部网络（IENet），该网络利用物体的外观和上下文信息进行鲁棒检测。针对小目标的特征提取、方案定位和分类，分别设计了三个定制模块：双向特征融合模块（Bi FFM）、上下文推理模块（CRM）和上下文特征增强模块（CFAM）。具体而言，Bi-FFM通过将CNN中更深层次的语义特征转移到更低层次，将更低层次的细节特征转移到更深层次来捕获对象的内部特征，这不仅利用了卷积特征的层次结构，而且通过上下文关系来促进其预测。CRM通过上下文推理提高区域建议的质量，上下文推理利用容易检测到的对象帮助理解困难的对象。CFAM学习通过CRM生成的区域建议之间的成对关系，并利用这种关系生成与区域建议关联的全局特征信息，以进行准确分类。Fang等人以日常生活中的小对象检测为重点，利用MS-COCO数据集的一个子集来构建小对象数据库，并提出了一种基于更快的R-CNN的更灵活的上下文信息集成方法。它们裁剪围绕提议区域的八个相应上下文区域，包括左上、中上、右上、左中、右中、左下、中下和右下。需要区分这八个上下文子窗口是否跨越要素图的边界。也就是说，它们将有效的上下文窗口添加到区域建议中，并且只添加分类信息，而不是包含分类和回归信息的完整信息。这样可以在一定程度上提高小目标检测的精度。Fu等人【103】提出了一种新的用于小对象检测的上下文推理方法，该方法对对象之间固有的语义和空间布局关系进行建模和推断。基于初始的区域特征，他们首先设计一个语义模块来建模稀疏的语义关系。此外，他们还设计了一个空间布局模块，根据位置和形状信息对稀疏空间布局关系进行建模。然后将二者输入到上下文推理模块中，对上下文信息进行整合，再与原始区域特征进行融合，进行回归和分类。实验结果表明，该方案能有效提高小目标检测的性能。与上述三种方案不同，Lim等人【104】提出了一种新的方法，该方法通过串联多尺度特征，利用来自不同层的额外特征作为上下文。此外，他们还介绍了一种带有注意机制的检测方法，该方法可以聚焦图像中的对象，并且可以包含来自目标层的上下文信息。后来，Yan等人【105】提出了一种称为LocalNet的单级检测器，该检测器更加关注详细的信息建模。LocalNet的目的是在早期阶段保留更详细的信息，以增强小对象的表示。此外，他们还设计了一个局部细节上下文模块，以增强检测层的语义，从而重新引入网络中丢失的细节，并在有限的感受野范围内利用局部上下文。

以遥感小目标检测为重点，Liu等人[106]构建了一个多分量融合网络（MCFN），以提高遥感图像中小目标检测的准确性。他们首先设计了一个双金字塔融合网络，该网络通过编码和解码操作将空间和语义线索紧密连接起来，以提取小对象的特征。然后采用相对区域建议网络，充分捕捉小对象样本和部分对象的特征。最后，在最终检测之前，他们向建议区域添加上下文信息，以获得对背景干扰的鲁棒性。特征间图和不同尺度的特征图对网络的贡献不同。为了进一步增强遥感图像中检测小对象的有效权重，Yang等人【107】开发了一个初始平行注意网络，即IPAN。它包含三个并行模块：多尺度注意模块、上下文注意模块和通道注意模块。语境注意模块将广泛的语境线索编码到局部特征中，从而增强表征能力。IPAN不仅可以提取丰富的多尺度、上下文特征和不同通道中全局特征的相互依赖性，而且可以基于注意机制提取对象对另一个对象的长期依赖性，这有助于小对象检测。与MCFN【106】和IPAN【107】不同，Liang等人【108】提出了一种基于特征融合和缩放的SSD（FS-SSD），用于无人机图像中的小目标检测。除了FSSSD学习到的深层特征外，还提出了空间上下文分析，通过将对象空间关系纳入到对象重新检测中，进一步提高检测精度。将不同对象实例之间的类间距离和类内距离作为空间上下文进行计算，这对于多类小对象的检测是有效的。随后，Cheng等人【109】设计了上下文特征增强模块，以利用全局上下文线索，并通过使用指示是否存在对象类的图像级上下文信息，有选择地增强类别软件特征。此外，它们还利用上下文编码丢失对模型训练进行正则化，从而促进对象检测器更好地理解场景，并缩小预测中可能的对象类别。

除了小人脸检测、日常生活中的小目标检测和遥感中的小目标检测之外，基于上下文的信息也被用于其他领域的小目标检测

Bosquet等人【73】开发了一个完全卷积的网络，专注于视频中的小目标。该网络包括一种早期视觉注意机制，称为区域上下文网络（RCN），用于选择具有一个或多个小对象及其上下文的最有希望的区域，并将其作为一组不相交的区域返回。过滤后的特征地图只包含最可能包含小对象的区域，通过网络转发到最终区域建议网络（RPN），该网络为最终分类阶段提供信息。RCN是通过更精细的空间分辨率提高定位精度的关键，因为它具有更精细的全局有效步长、更高的帧速率和更低的内存开销。CNN中的细粒度特征对于网络精确定位小的或部分遮挡的对象至关重要。为了缓解深层CNN难以为高级特征图提取足够的区分细粒度特征的问题，Guan等人【110】首先以自上而下的顺序构建更大、更有意义的特征图，并将其串联，然后通过金字塔池融合多级上下文信息，构建上下文感知特征。因此，实现了一个称为语义上下文感知网络（SCAN）的统一框架，以提高目标检测的准确性。Cui等人【111】通过构建高分辨率、强语义的特征地图，设计了一种上下文感知块网络（CABNet），以提高交通标志和小头等小对象的检测性能。为了在内部增强具有高空间分辨率的特征地图的表示能力，他们设计了上下文感知块（CAB），该块利用金字塔扩展卷积来合并多级上下文信息，而不会丢失特征地图的原始分辨率。然后，他们以相对较小的下采样因子将CAB组装到截断骨干网络的末端，并丢弃所有后续层。Hong等人以小人检测为重点，提出了一种尺度选择金字塔网络（SSPNet），该网络由三个模块组成，包括上下文注意模块（CAM）、尺度增强模块（SEM）和尺度选择模块（SSM）。CAM考虑上下文信息来生成层次化的注意热图。扫描电镜（SEM）突出了不同层面上特定尺度的特征，使探测器聚焦于特定尺度的物体，而不是广阔的背景。SSM利用相邻层之间的关系，在浅层和深层之间实现适当的特征共享，从而避免了不同层之间梯度计算的不一致性。在表5中，我们总结了上述基于上下文的方案的优缺点。

这些方法主要是通过学习对象与周围信息之间的关系来获取感兴趣区域周围的线索和改进对象分类。然而，并非所有基于上下文的信息都有助于检测。冗余的上下文信息还会导致信息噪音，从而影响小对象的性能。另一方面，这些方法没有考虑到场景中可能缺少上下文信息，也没有有针对性地利用场景中易于检测的结果来帮助检测小对象。

### 3.2.3. Multi-scale representation learning
多尺度表示学习也是一种有效的小目标检测策略。首先，我们简要展示了图3中的四种经典方法，包括特征化图像金字塔、单一特征映射、金字塔特征层次和特征金字塔网络

然后，详细介绍了基于它们的一些改进方法。

如图3（a）所示，以前的物体检测器通常采用特征化的图像金字塔来检测不同尺度的物体。即，他们将输入图像调整为许多不同的尺度，并学习多个检测器，每个检测器负责一定范围的尺度。随着深度学习的发展，Liu等人[113]提出了一种图像金字塔制导网络（IPGNet），以确保每一层都有丰富的空间和语义信息。它由两个主要模块组成：IPG转换和融合模块。即使在主干的最深阶段，IPG转换模块仍保留足够的空间信息，用于边界盒回归和分类。此外，IPG融合模块还融合了图像金字塔特征和主干特征。该方案的主要思想是在骨干网中引入IPG来处理信息不平衡问题，从而缓解小对象特征的消失。然而，由于内存消耗和推理时间的快速增加，这种方法的计算代价很高。Liu等人

【85】分析了小目标检测所依赖的因素以及效率和性能之间的权衡，并提出了一种高分辨率检测网络（HRDNet）。它包括一个重要的部分，即多深度图像金字塔网络（MD-IPN）。MD-IPN利用多个深度主干维护多个位置信息。通过从高分辨率到低分辨率提取各种特征，可以提高小目标检测性能，同时保持大中型目标的检测性能。为了减少这些特征之间的信息不平衡，还提出了一种多尺度特征金字塔网络来对齐和融合MD-IPN生成的多尺度特征组。HRDNet不仅可以在高分辨率下获取小对象的更多细节，还可以通过集成多深度、多尺度的网络来保证有效性和效率。

一些检测方案（如更快的R-CNN[37]和R-FCN[114]）使用CNN在单个输入尺度上计算的最顶层特征图来预测具有不同纵横比和尺度的候选边界框（见图3（b））。但是，由于连续下采样，最顶层上的小对象几乎没有信息。这可能会影响小对象的检测性能。为此，Liu等人[45]提出了一种名为SSD的单激发检测器，它可以从多层检测具有不同尺度和纵横比的对象。然后，从多个层进行预测，其中每个层负责一定比例的对象。实际上，深层CNN中的网络内特征层次结构生成了不同空间分辨率的特征图，同时引入了由不同深度引起的较大语义间隙（见图3（c））。也就是说，深层CNN学习不同层次的层次特征，从不同尺度的对象中获取信息。因此，SSD利用较浅层的特征检测较小的对象，而利用较深层的特征检测较大的对象。然后，提出了一些基于ssdbase的算法。

Cao等人[115]提出了一种在SSD中引入上下文线索的多级特征融合方法，即特征融合SSD（FFSSD）。此外，在融合阶段采用级联和元素和模块。为了进一步提高小目标的检测精度，Xu等人[116]提出了一种多尺度反卷积SSD，称为MDSSD。它们通过多尺度反褶积融合模块将具有语义信息的高层特征注入到底层特征中，得到信息丰富的特征图。特别是，它们在最顶层之前的多尺度特征上实现反褶积层，并将其与一些底层特征合并，以生成更多的语义特征图。此外，他们还添加了骨干网输出的conv3\u 3用于预测，以提高CNN对小目标的检测性能。与这两种架构不同，Sun等人【117】提出了一种掩模引导SSD，通过增强上下文信息的功能和引入分割掩模来消除背景区域，从而提高SSD检测小对象的性能。它由检测分支和分割分支组成。他们构建了一个特征融合模块，使检测分支能够利用上下文信息获得高分辨率的特征地图。分割分支主要通过扩展卷积来构建，为检测分支提供额外的上下文线索。此外，利用分割特征生成掩模，用于指导检测分支在潜在前景区域中找到目标。

受人类视觉系统中感受野（RFs）结构的启发，Liu等人【118】提出了一种新的RF块（RFB），该块考虑了RFs大小和偏心率之间的关系，以增强特征的可辨别性和鲁棒性。通过将RFB组装到SSD顶部，构建RFBNet检测器。RFBNet在保持实时速度的同时，可以达到高级甚深探测器的性能。与RFBNet类似，Li等人【119】开发了一种新的三叉戟网络（TridentNet），旨在生成具有统一表示力的特定比例特征地图。他们构建了一个平行的多分支结构，其中每个分支共享相同的参数，但具有不同的感受野。为了改进无人机捕获图像中小目标的检测，Razaak等人【120】提出了一种在SSD目标检测器上使用反卷积模块进行低级别特征组合的多尺度方法。后来，Han等人【121】引入D-RFB模块，可以增强特征图的表示能力。与D-RFB模块集成的D-RFBNet可以更准确地检测无人机图像中的小目标。

为了结合单一特征映射和金字塔特征层次之间的优势，Lin等人[122]提出了特征金字塔网络（FPN）。它构建了一个具有横向连接的自顶向下的体系结构，以生成一系列比例不变的特征映射，并在这些特征金字塔上学习多个与比例相关的分类器（见图3（d））具体而言，浅层空间丰富的特征通过深层语义丰富的特征得到加强。这些横向和自上而下的特征通过串联或元素求和进行集成。随后，提出了FPN的许多变体。与传统检测器相比，这些方法通过对特征金字塔块的一些修改，在检测精度上有了显著的提高。

为了弥补现有方法在检测遥感小目标方面的不足，Qu等人[123]提出了一种扩展卷积和特征融合检测器DFSSD。该检测器利用FPN的结构，将高分辨率的低层特征图与语义丰富的高层特征图进行融合。它还通过采用扩张卷积来提高DFSSD网络三级特征图的感受野。随后，Liang等人【108】提出了一种基于特征融合和缩放的SSD检测器，名为FS-SSD，用于无人机图像中的小目标检测。他们在反褶积模块中添加了一个额外的缩放分支，并使用平均池操作来形成一个特征金字塔。然后对原始特征融合分支进行调整，使其更好地适应小目标检测任务。最后，使用反褶积模块和特征融合模块生成的这两个特征金字塔一起进行预测。与DFSSD和FS-SSD不同，Liu等人【106】构建了一个多分量融合网络（MCFN），它包含三个主要部分：双金字塔融合网络（DPFN）、相对区域提议网络（RRPN）和上下文信息网络（CIN）。具体来说，DPFN通过编码和解码操作，将空间和语义信息紧密地连接起来，以提取小对象的特征。RRPN能够充分捕获小对象样本和部分对象的特征。CIN能够实现对背景干扰的鲁棒性。与多分量融合网络（MCFN）不同，Liu等人[124]构建了一个多分支并行特征金字塔网络（MPFPN），以提取无人机捕获图像中小尺寸物体更丰富的特征信息。并行分支旨在恢复深层中缺失的特征。为了减弱背景噪声推理和聚焦目标信息的影响，在MPFPN中引入了有监督的空间注意模块。此外，他们在快速R-CNN阶段使用级联架构，以获得更强大的定位能力。除了上述方法外，还有一些方法[54125]试图使用双向策略。Zheng等人[125]提出了一种双向阶梯串联特征金字塔方法。阶梯式拼接策略有助于避免金字塔构建过程中当前层的信息丢失，双向方案确保融合特征同时包含细节和语义信息。此外，还设计了注意交互模块，以更好地聚合双流功能，从而提高网络性能。同样，Li等人[54]提出了跨层注意网络（CANet）。他们首先设计了一个上采样和下采样特征金字塔，通过双向融合深度和浅层特征以及跳过连接来获得更丰富的上下文信息。然后，提出了一种跨层注意模块来捕获每层中小对象的非局部关联，并通过跨层集成和平衡进一步增强其表示能力。为了解决特征金字塔中自上而下的操作会导致不同层次的特征相互影响的问题，Cheng等人[126]提出了感知特征金字塔网络（AFPN）。AFPN学习特征金字塔中较高级别特征的向量，以获得清晰的特征。此外，通过使用新的组分配策略，可以更好地分配正负标签。

除了遥感图像中的小目标检测外，日常生活中的小目标检测也引起了研究人员的广泛关注。Liang等人【127】开发了一种名为深度特征金字塔网络（DFPN）的新型检测器。DFPN采用横向连接的特征金字塔结构，使小对象的语义特征更加敏感。此外，他们还设计了专门的锚来检测大分辨率图像中的小目标，然后训练具有焦点丢失的网络。为了缓解目标检测训练中样本水平、特征水平和目标水平的不平衡，Pang等人[128]提出了一个称为Libra R-CNN的有效框架，该框架分别集成了三个新组件：IoU平衡采样、平衡特征金字塔和平衡L1损失。得益于整体平衡设计，Libra R-CNN显著提高了小物体的检测性能。与这两种方法不同，Zheng等人[129]提出了一种交互式多尺度特征表示增强（IMFRE）策略，该策略包括两部分：多尺度辅助增强网络（MAEN）和自适应交互模块（AIM）。MAEN是针对多输入下的特征交互而提出的。它们将输入缩放到与预测层对应的多个尺度，只通过轻量级模块提取更详细的特征，以增强原始特征。AIM旨在聚合相邻层的特征。该方法在不改变原始网络结构的情况下，可以灵活地实现对小目标检测的改进。考虑到实时嵌入式设备上的小对象检测，Chen等人[130]提出了RHF网络，一种新型递归混合融合金字塔网络。所提出的RHFNet有两个新颖之处：即双向融合模块、递归级联和整形模块。前者可以融合自顶向下和自下而上方向的特征映射，生成灵活的特征金字塔，用于小目标检测。后者不仅可以递归地连接深层的高级语义特征，还可以重塑较浅层的空间丰富特征，以防止小对象消失。RHFNet在融合过程中采用了低计算成本和特征保持操作，因此在嵌入式设备上具有高效和准确的性能。

为了在广阔的视野和巨大的背景中检测微小的人，Liu等人【131】设计了一种特征重缩放和融合（SFRF）方法。通过设计一种非参数自适应稠密感知算法，该算法可以自动选择并生成具有高密度分布的微小物体的新尺寸特征地图。为了增强特征表示，他们还使用多对一策略对FPN层进行特征融合。Gong等人【132】认为FPN中相邻层之间自上而下的连接会对微小物体检测产生负面影响。他们引入了一种称为融合因子的新概念来控制从深层到浅层的信息传输，以使FPN适应微小目标检测。此外，他们还探讨了如何通过统计策略估计特定数据集的融合因子的有效值。经过一系列的实验和分析，他们发现估计值取决于分布在每一层中的对象数量。当使用适当的融合因子配置FPN时，网络可以在微小物体上实现显著的检测性能。虽然大多数现有的方法通过结合深层的上下文特征来丰富浅层的特征，但由于不同层之间梯度计算的不一致性的限制，FPN中的浅层没有被充分利用来检测微小对象。为此，Hong等人[112]提出了一种用于微小人物检测的尺度选择金字塔网络（SSPNet）。它由三个部分组成，包括上下文注意模块（CAM）、尺度增强模块（SEM）和尺度选择模块（SSM）。CAM考虑上下文信息来生成层次化的注意热图。扫描电镜（SEM）突出了不同层面上特定尺度的特征，使探测器聚焦于特定尺度的物体，而不是广阔的背景。SSM利用相邻层之间的关系，在浅层和深层之间实现适当的特征共享，从而避免了不同层之间梯度计算的不一致性。表6列出了上述多尺度表征学习方法的优缺点。

### 3.2.4. Anchor mechanism


# 5. Conclusion
本文全面讨论了小对象或微小对象数据集、小对象或微小对象的定义、小对象或微小对象检测技术、小对象或微小对象检测性能分析以及小对象检测的发展方向。这项工作为小对象检测社区带来了最新和彻底的调查。同时，我们希望这篇综述能够为研究人员进一步研究小目标检测系统提供指导。
