# 0. abstract

我们提出了一种通过对抗过程估计生成模型的新框架，其中我们同时训练两个模型：捕获数据分布的生成模型G和估计样本来自训练数据而不是G的概率的判别模型D。G的训练过程是最大化D出错的概率。这个框架对应于一个极小极大两人博弈。在任意函数G和D的空间中，存在唯一解，其中G恢复训练数据的分布，D处处等于1/2。在G和D由多层感知器定义的情况下，整个系统可以用反向传播来训练。在训练或生成样本的过程中，不需要任何马尔可夫链或展开的近似推理网络。通过对生成的样本进行定性和定量的评估，实验证明了该框架的潜力。

# 1. introduction

深度学习的前景是发现丰富的分层模型[2]，这些模型表示人工智能应用程序中遇到的各种数据的概率分布，例如自然图像、包含语音的音频波形和自然语言语料库中的符号。到目前为止，深度学习中最引人注目的成功涉及歧视性模型，通常是那些将高维、丰富的感觉输入映射到类别标签上的模型[14，20]。这些惊人的成功主要是基于反向传播和丢弃算法，使用具有特别良好的梯度的分段线性单元[17，8，9]。深度生成性模型的影响较小，因为很难近似最大似然估计和相关战略中出现的许多棘手的概率计算，也因为很难在生成性背景下利用分段线性单位的好处。我们提出了一种新的生成性模型估计方法来避开这些困难。

在所提出的对抗性网络框架中，生成模型与对手进行较量：识别模型学习确定样本是来自模型分布还是来自数据分布。生成性模式可以被想象为类似于一群造假者，试图制造假币并在不被发现的情况下使用，而辨别性模式则类似于警察，试图检测假币。这个游戏中的竞争驱使双方改进他们的方法，直到仿冒品与正品无法辨别。

该框架可以为多种模型和优化算法产生特定的训练算法。本文讨论了产生式模型通过多层感知器传递随机噪声产生样本的特殊情况，而判别模型也是多层感知器。我们将这种特殊情况称为对抗性网。在这种情况下，我们可以只使用非常成功的反向传播和丢弃算法来训练这两个模型[16]，并且只使用前向传播来训练生成模型的样本。不需要近似推论或马尔可夫链。

# 2. related work

直到最近，大多数关于深度生成模型的工作都集中在提供概率分布函数的参数说明的模型上。然后，可以通过最大化对数似然来训练该模型。在这一系列模型中，最成功的可能是深度玻尔兹曼机器[25]。这类模型通常具有难以处理的似然函数，因此需要对似然梯度进行多次近似。这些困难推动了“产生式机器”的发展--这种模型不明确地表示可能性，但能够从期望的分布中生成样本。生成性随机网络[4]是生成性机器的一个例子，它可以用精确的反向传播来训练，而不是用Boltzmann机器所需的大量近似来训练。这项工作通过消除生成随机网络中使用的马尔科夫链扩展了生成机的概念。我们的工作通过产生性过程反向传播导数，通过观察到
$$
\lim _{\sigma \rightarrow 0} \nabla_{\boldsymbol{x}} \mathbb{E}_{\epsilon \sim \mathcal{N}\left(0, \sigma^{2} \boldsymbol{I}\right)} f(\boldsymbol{x}+\epsilon)=\nabla_{\boldsymbol{x}} f(\boldsymbol{x})
$$
当我们开发这项工作时，我们并不知道Kingma和Wling[18]和Rezende等人。[23]发展了更一般的随机反向传播规则，允许通过有限方差的高斯分布进行反向传播，并向后传播到协方差参数和平均值。这些反向传播规则可以让人们学习生成器的条件方差，在本工作中，我们将其视为超参数。Kingma和Wling[18]和Rezende等人。[23]使用随机反向传播来训练变分自动编码器(VAE)。像生成性对抗性网络一样，变分自动编码器将一个可微生成器网络与第二个神经网络配对。与生成性对抗网络不同，VAE中的第二个网络是执行近似推理的识别模型。GAN需要通过可见单元进行区分，因此不能对离散数据建模，而VAE需要通过隐藏单元进行区分，因此不能具有离散的潜在变量。其他类似VEA的方法也存在[12，22]，但与我们的方法关系不那么密切。

以前的工作也采取了使用歧视性标准来训练生成模型的方法[29，13]。这些方法使用的标准对于深度生成模型来说是难以处理的。这些方法甚至很难对深层模型进行近似，因为它们涉及的概率比不能使用下限概率的变分近似来近似。噪声对比估计(NCE)[13]涉及通过学习使模型用于区分数据和固定噪声分布的权重来训练生成模型。使用先前训练的模型作为噪声分布允许训练质量不断提高的模型序列。这可以被视为一种精神上类似于对抗性网络游戏中使用的正式竞争的非正式竞争机制。NCE的主要局限性是，它的“鉴别器”是由噪声分布的概率密度和模型分布的概率密度之比定义的，因此需要评估和反向传播这两种密度的能力。

以前的一些工作使用了让两个神经网络竞争的一般概念。最相关的工作是可预测性最小化[26]。在可预测性最小化中，神经网络中的每个隐藏单元被训练成不同于第二网络的输出，第二网络在给定所有其他隐藏单元的值的情况下预测该隐藏单元的值。这项工作与可预测性最小化有三个重要的区别：1)在这项工作中，网络之间的竞争是唯一的训练标准，并且它本身就足以训练网络。可预测性最小化只是一种正则化，它鼓励神经网络的隐含单元在完成其他任务时在统计上独立；它不是主要的训练标准。2)竞争的性质不同。在可预测性最小化中，比较两个网络的输出，其中一个网络试图使输出相似，而另一个网络试图使输出不同。所讨论的输出是单个标量。在GANS中，一个网络产生一个丰富的高维向量，用作另一个网络的输入，并试图选择另一个网络不知道如何处理的输入。3)学习过程的规范不同。可预测性最小化被描述为一个目标函数最小化的优化问题，学习逼近目标函数的最小值。GAN基于极小极大博弈，而不是优化问题，并且具有一个代理寻求最大化而另一个寻求最小化的值函数。游戏在一个鞍点结束，该鞍点对于一个玩家的策略是最小的，相对于另一个玩家的策略是最大的。

生成性对抗性网络有时与“对抗性例子”的相关概念混淆[28]。对抗性例子是通过直接对分类网络的输入使用基于梯度的优化来找到的例子，以便找到与数据相似但被错误分类的例子。这与目前的工作不同，因为对抗性例子不是训练生成模型的机制。相反，敌意的例子主要是一种分析工具，用来表明神经网络的行为方式很有趣，通常会自信地对两幅图像进行不同的分类，并具有很高的置信度，即使人类观察者察觉不到它们之间的差异。这种对抗性例子的存在确实表明，生成性对抗性网络训练可能是低效的，因为它们表明，有可能使现代区分网络自信地识别一类，而不模仿该类的任何人类可感知的属性。

# 3. adversarial nets

当两个模型都是多层感知器时，对抗性建模框架最容易应用。为了了解生成器在数据x上的分布Pg，我们定义了关于输入噪声变量Pz(Z)的先验，然后将到数据空间的映射表示为G(z；θg)，其中G是由参数为θg的多层感知器表示的可微函数。我们还定义了第二个输出单标量的多层感知器D(x；θd)。D(X)表示x来自数据而不是Pg的概率。我们训练D以最大化为训练样本和来自G的样本分配正确标签的概率。我们同时训练G以最小化LOG(1−D(G(Z)。换句话说，D和G用值函数V(G，D)玩下面的两人极小极大对策：
$$
\min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}(\boldsymbol{x})}[\log D(\boldsymbol{x})]+\mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}(\boldsymbol{z})}[\log (1-D(G(\boldsymbol{z})))]
$$
在下一节中，我们给出了对抗性网络的理论分析，本质上表明，当G和D被赋予足够的容量时，即在非参数限制下，训练标准允许恢复数据生成分布。有关该方法的不那么正式、更具教育性的解释，请参见图1。在实践中，我们必须使用迭代的、数值的方法来实现游戏。在训练的内环中优化D以完成在计算上是令人望而却步的，并且无限的数据集将导致过拟合。取而代之的是，我们在优化D的k个步骤和优化G的一个步骤之间交替，这导致D保持在其最优解附近，只要G变化足够慢。该过程在算法1中正式给出。

在实践中，公式1可能不会为G提供足够的梯度来很好地学习。在学习初期，当G较差时，D可以高置信度地拒绝样本，因为它们与训练数据明显不同。在这种情况下，LOG(1−D(G(Z)饱和。不是训练G来最小化LOG(1−D(G(Z)，我们可以训练G来最大化LOG  D(G(Z))。这个目标函数导致了G和D的动力学相同的固定点，但在学习初期提供了更强的梯度。