# Abstract

最近提出了  DETR，以消除在对象检测中对许多手工设计组件的需求，同时展示了良好的性能。然而，由于 Transformer  注意力模块在处理图像特征图方面的局限性，它存在收敛速度慢和特征空间分辨率有限的问题。为了缓解这些问题，我们提出了可变形  DETR，其注意力模块只关注参考周围的一小组关键采样点。可变形 DETR 可以比 DETR（尤其是在小物体上）获得更好的性能，训练时间少 10 倍。在 COCO  基准上的大量实验证明了我们方法的有效性。

# 1. Introduction

现代目标检测器采用许多手工制作的组件（Liu  等人，2020），例如锚点生成、基于规则的训练目标分配、非极大值抑制 (NMS) 后处理。它们不是完全端到端的。最近，Carion 等人。 （2020 年）提出  DETR 以消除对此类手工组件的需求，并构建了第一个完全端到端的物体检测器，实现了极具竞争力的性能。 DETR 通过结合卷积神经网络 (CNN) 和  Transformer (Vaswani et al., 2017) 编码器-解码器，利用简单的架构。在适当设计的训练信号下，他们利用 Transformer  的多功能和强大的关系建模能力来替换手工制作的规则。

尽管  DETR 具有有趣的设计和良好的性能，但它也有其自身的问题：（1）与现有的目标检测器相比，它需要更长的训练 epoch 才能收敛。例如，在 COCO (Lin  et al., 2014) 基准测试中，DETR 需要 500 个 epoch 才能收敛，这比 Faster R-CNN (Ren et al., 2015)  慢了大约 10 到 20 倍。 (2) DETR  在检测小物体时性能相对较低。现代目标检测器通常利用多尺度特征，从高分辨率特征图中检测小目标。同时，高分辨率特征图导致 DETR  的复杂性令人无法接受。上述问题主要归因于 Transformer  组件在处理图像特征图方面的不足。在初始化时，注意力模块将几乎统一的注意力权重投射到特征图中的所有像素上。要学习注意力权重以专注于稀疏的有意义的位置，需要长时间的训练周期。另一方面，Transformer  编码器中的注意力权重计算是 w.r.t 的二次计算。像素数。因此，处理高分辨率特征图具有非常高的计算和存储复杂性。

在图像域中，可变形卷积  (Dai et al., 2017) 是处理稀疏空间位置的强大而有效的机制。它自然避免了上述问题。而它缺乏元素关系建模机制，这是DETR成功的关键。

在本文中，我们提出了可变形  DETR，它缓解了 DETR 的收敛速度慢和复杂度高的问题。它结合了可变形卷积的稀疏空间采样和 Transformer  的关系建模能力的优点。我们提出了可变形注意力模块，它关注一小组采样位置，作为所有特征图像素中突出关键元素的预过滤器。该模块可以自然地扩展到聚合多尺度特征，而无需  FPN 的帮助（Lin 等人，2017a）。在 Deformable DETR 中，我们利用（多尺度）可变形注意模块来代替处理特征图的 Transformer  注意模块，如图 1 所示。

可变形 DETR  为我们提供了利用端到端目标检测器变体的可能性，这要归功于其快速收敛、计算和内存效率。我们探索了一种简单有效的迭代边界框细化机制来提高检测性能。我们还尝试了一个两阶段的可变形  DETR，其中区域建议也由可变形 DETR 的变体生成，进一步输入解码器以进行迭代边界框细化。

COCO  (Lin et al., 2014) 基准上的大量实验证明了我们方法的有效性。与 DETR 相比，Deformable DETR 可以在训练 epoch 少  10 倍的情况下获得更好的性能（尤其是在小物体上）。所提出的两阶段可变形 DETR 变体可以进一步提高性能。

# 2. Related work

## 高效的注意力机制。

Transformers  (V aswani et al., 2017) 涉及自我注意和交叉注意机制。 Transformers  最知名的问题之一是大量关键元素数量的高时间和内存复杂性，这在许多情况下阻碍了模型的可扩展性。最近，针对这个问题做了很多努力（Tay et al.,  2020b），在实践中大致可以分为三类。

第一类是在键上使用预定义的稀疏注意力模式。最直接的范例是将注意力模式限制为固定的本地窗口。大多数作品（Liu 等人，2018a；Parmar  等人，2018；Child 等人，2019；Huang 等人，2019；Ho 等人，2019；Wang 等人，2020a；Hu 等人，  2019；Ramachandran 等人，2019；Qiu 等人，2019；Beltagy 等人，2020；Ainslie 等人，2020；Zaheer  等人，2020）遵循这一范式。尽管将注意力模式限制在局部邻域可以降低复杂性，但它会丢失全局信息。为了补偿，Child 等人。 （2019）；黄等人。  （2019）；何等人。 （2019）；王等人。 (2020a) 以固定的时间间隔关注关键元素，以显着增加键的感受野。贝尔塔吉等人。 （2020）；安斯利等人。  （2020）；扎希尔等人。 (2020) 允许少量特殊令牌访问所有关键元素。扎希尔等人。 （2020）；邱等人。  （2019）还添加了一些预先固定的稀疏注意力模式来直接关注遥远的关键元素。

第二类是学习数据依赖的稀疏注意力。基塔耶夫等人。 （2020）提出了一种基于局部敏感散列（LSH）的注意力，它将查询和关键元素散列到不同的箱中。 Roy  等人提出了类似的想法。 (2020)，其中 k-means 找出最相关的键。泰等人。 （2020a）学习块置换以实现块稀疏注意力。

第三类是探索self-attention中的low-rank属性。王等人。  （2020b）通过大小维度上的线性投影而不是通道维度来减少关键元素的数量。卡塔罗普洛斯等人。 （2020）；乔罗曼斯基等人。  （2020）通过核化近似重写了selfattention的计算。

在图像领域，高效注意力机制的设计（例如，Parmar  等人（2018）；Child 等人（2019）；Huang 等人（2019）；Ho 等人（2019）；Wang 等人。 (2020a); Hu et al.  (2019); Ramachandran et al. (2019)) 仍然限于第一类。尽管理论上降低了复杂性，Ramachandran 等人。  （2019）；胡等人。 (2019) 承认，由于内存访问模式的内在限制，这种方法的实现速度比具有相同 FLOP 的传统卷积要慢得多（至少慢 3 倍）。

我们提出的可变形注意模块受到可变形卷积的启发，属于第二类。它只关注从查询元素的特征预测的一小部分固定采样点。与  Ramachandran 等人不同。 （2019）；胡等人。 (2019)，在相同的 FLOPs 下，可变形注意力仅比传统卷积稍慢。

## 用于目标检测的多尺度特征表示。

目标检测的主要困难之一是有效地表示不同尺度的目标。现代物体检测器通常利用多尺度特征来适应这一点。作为开创性的工作之一，FPN  (Lin et al., 2017a) 提出了一种自上而下的路径来组合多尺度特征。 PANet (Liu et al., 2018b) 在 FPN  的顶部进一步增加了一个自下而上的路径。孔等人。 （2018）通过全局注意力操作结合了所有尺度的特征。赵等人。 (2019) 提出了一个 U  形模块来融合多尺度特征。最近，NAS-FPN (Ghiasi et al., 2019) 和 Auto-FPN (Xu et al., 2019)  被提出通过神经架构搜索自动设计跨尺度连接。谭等人。 (2020) 提出了 BiFPN，它是 PANet  的重复简化版本。我们提出的多尺度可变形注意模块可以通过注意机制自然地聚合多尺度特征图，而无需这些特征金字塔网络的帮助。

# 3. 回顾transformer和detr

## Transformer中的多头注意力。

Transformers (V aswani et al., 2017)  是一种基于机器翻译注意机制的网络架构。给定一个查询元素（例如，输出句子中的目标词）和一组关键元素（例如，输入句子中的源词），多头注意力模块根据衡量的注意力权重自适应地聚合关键内容查询密钥对的兼容性。为了让模型关注来自不同表示子空间和不同位置的内容，不同注意力头的输出与可学习的权重线性聚合。令 $q \in \Omega_{q}$ 用表示特征 $\boldsymbol{z}_{q} \in \mathbb{R}^{C}$ 索引一个查询元素，$k \in \Omega_{k}$ 用表示特征$\boldsymbol{x}_{k} \in \mathbb{R}^{C}$ 索引一个关键元素，其中 $C$ 是特征维度，$\Omega_{q}$ 和 $\Omega_{k}$分别指定查询和关键元素的集合.然后计算多头注意力特征
$$
\operatorname{MultiHeadAttn}\left(\boldsymbol{z}_{q}, \boldsymbol{x}\right)=\sum_{m=1}^{M} \boldsymbol{W}_{m}\left[\sum_{k \in \Omega_{k}} A_{m q k} \cdot \boldsymbol{W}_{m}^{\prime} \boldsymbol{x}_{k}\right]
$$
其中$m$表示注意头，$\boldsymbol{W}_{m}^{\prime} \in \mathbb{R}^{C_{v} \times C}$和$\boldsymbol{W}_{m} \in \mathbb{R}^{C \times C_{v}}$具有可学习的权重(默认情况下，$C_{v}=C / M$)。attention权重$A_{m q k} \propto \exp \left\{\frac{\boldsymbol{z}_{q}^{T} \boldsymbol{U}_{m}^{T} \boldsymbol{V}_{m} \boldsymbol{x}_{k}}{\sqrt{C_{v}}}\right\}$被归一化为$\sum_{k \in \Omega_{k}} A_{m q k}=1$，其中$\boldsymbol{U}_{m}, \boldsymbol{V}_{m} \in \mathbb{R}^{C_{v} \times C}$也是可学习权重。为了消除不同的空间位置歧义，表示特征$\boldsymbol{z}_{q}$和$\boldsymbol{x}_{k}$通常是元素内容和位置嵌入的拼接/求和。

Transformer有两个已知的问题。一是在融合之前，需要很长的训练计划。假设查询数为$N_{q}$，关键元素数为$N_{k}$。通常，在适当的参数初始化的情况下，$\boldsymbol{U}_{m} \boldsymbol{z}_{q}$和$\boldsymbol{V}_{m} \boldsymbol{x}_{k}$服从均值为0和方差为1的分布，这使得当$N_{k}$较大时，注意权重$A_{m q k} \approx \frac{1}{N_{k}}$。这将导致输入要素的梯度不明确。因此，需要长时间的训练计划，以便注意力权重可以集中在特定的关键字上。在图像域中，关键元素通常是图像像素，$N_{k}$可能非常大，并且收敛是乏味的。

另一方面，由于有大量的查询和关键元素，多头注意的计算和存储复杂性可能非常高。方程的计算复杂性。1为$O\left(N_{q} C^{2}+N_{k} C^{2}+N_{q} N_{k} C\right)$。在图像域中，查询和关键元素都是像素，$N_{q}=N_{k} \gg C$，复杂性由第三项所支配，如$O\left(N_{q} N_{k} C\right)$。因此，多头注意模块的复杂度随着特征图的大小呈二次曲线增长。

## DETR

DETR(Carion等人，2020)构建在Transformer编解码器架构之上，结合基于集合的匈牙利损失，通过二部匹配强制对每个地面真相边界框进行唯一预测。我们简要回顾一下网络体系结构，如下所示。

给定由cnn主干(例如Resnet(他等人，2016年))提取的输入特征映射$\boldsymbol{x} \in \mathbb{R}^{C \times H \times W}$，Detr利用标准的Transformer编解码器体系结构将输入特征映射转换为一组对象查询的特征。在解码器产生的目标查询特征之上加入3层前馈神经网络(FFN)和线性投影作为检测头。FFN作为回归分支来预测边界框坐标$\boldsymbol{b} \in[0,1]^{4}$，其中$\boldsymbol{b}=\left\{b_{x}, b_{y}, b_{w}, b_{h}\right\}$编码归一化的框中心坐标、框的高度和宽度(相对于图像大小)。线性投影作为分类分支，产生分类结果。

对于DETR中的Transformer编码器，查询和关键元素都是特征地图中的像素。输入是ResNet特征地图(带有编码的位置嵌入)。让$H$和$W$分别表示要素地图的高度和宽度。自我注意的计算复杂度为$O\left(H^{2} W^{2} C\right)$，并随空间大小呈二次曲线增长。

对于DETR中的Transformer解码器，输入包括来自编码器的特征映射和由可学习位置嵌入表示的N个对象查询(例如，N=100)。解码器中存在两种类型的注意模块，即交叉注意模块和自我注意模块。在交叉注意模块中，对象查询从特征地图中提取特征。Q元素是对象查询，K元素是编码器输出的特征地图。其中，$N_{q}=N, N_{k}=H \times W$，交叉注意的复杂度为$O\left(H W C^{2}+N H W C\right)$。复杂度随着要素地图的空间大小而线性增长。在自我注意模块中，对象查询相互交互，以捕捉它们之间的关系。查询和关键元素都是对象查询。其中，$N_{q}=N_{k}=N$，自我注意模块的复杂度为$O\left(2 N C^{2}+N^{2} C\right)$。对于中等数量的对象查询，其复杂性是可以接受的。

DETR是一种有吸引力的目标检测设计，它消除了对许多手动设计组件的需要。然而，它也有自己的问题。这些问题主要可归因于Transformer在将图像特征图作为关键元素处理时的注意力不足：(1)DETR在检测小目标方面的性能相对较低。现代物体探测器使用高分辨率特征图来更好地检测小物体。然而，高分辨率的特征映射会给DETR的Transformer编码器中的自我注意模块带来不可接受的复杂性，其复杂度是输入特征映射空间大小的平方。(2)与现代目标检测器相比，DETR需要更多的训练周期才能收敛。这主要是因为处理图像特征的注意模块很难训练。例如，在初始化时，交叉注意模块对整个特征图的注意力几乎是平均的。然而，在训练结束时，注意图被学习到非常稀疏，只专注于物体的末端。看来，DETR需要很长的训练计划才能学习到注意图中的如此重大变化。

# 4. Method

## 4.1 Deformable Transformers for End-to-End Object Detection

### Deformable Attention Module

在图像特征地图上应用变形金刚注意力的核心问题是它将查看所有可能的空间位置。为了解决这个问题，我们提出了一个可变形的注意模块。受可变形卷积(Dai等人，2017；朱等人，2019b)的启发，可变形注意模块只关注参考点周围的一小组关键采样点，而不考虑特征地图的空间大小，如图2所示。通过仅为每个查询分配少量固定数量的关键字，收敛和特征空间分辨率的问题可以得到缓解。

给定输入特征映射$\boldsymbol{x} \in \mathbb{R}^{C \times H \times W}$，让q索引具有内容特征$\boldsymbol{z}_{q}$和2-d参考点$\boldsymbol{p}_{q}$的查询元素，通过下式计算可变形注意力特征
$$
\operatorname{DeformAttn}\left(\boldsymbol{z}_{q}, \boldsymbol{p}_{q}, \boldsymbol{x}\right)=\sum_{m=1}^{M} \boldsymbol{W}_{m}\left[\sum_{k=1}^{K} A_{m q k} \cdot \boldsymbol{W}_{m}^{\prime} \boldsymbol{x}\left(\boldsymbol{p}_{q}+\Delta \boldsymbol{p}_{m q k}\right)\right]
$$
其中，$m$索引注意力头部，$k$索引采样关键字，$K$是采样关键字总数($K \ll H W$)。$\Delta\boldsymbol{p}_{m q k}$和 $A_{m q k}$分别表示第m个注意力头部中第k个采样点的采样偏移量和关注权重。标量注意权重$A_{m q k}$位于范围[0，1]内，归一化为$\sum_{k=1}^{K} A_{m q k}=1 $。$ \Delta \boldsymbol{p}_{m q k} \in \mathbb{R}^{2}$是具有无约束范围的2维实数。由于$\boldsymbol{p}_{q}+\Delta \boldsymbol{p}_{m q k}$是分数的，所以采用了Dai等人的双线性插值法。(2017)计算$\boldsymbol{x}\left(\boldsymbol{p}_{q}+\Delta \boldsymbol{p}_{m q k}\right)$。$\Delta\boldsymbol{p}_{m q k}$和 $A_{m q k}$都是通过在查询特征$\boldsymbol{z}_{q}$上的线性投影获得的。在实现中，查询特征$\boldsymbol{z}_{q}$被馈送到$3MK$个通道的线性投影算子，其中前$2MK$个通道对采样偏移量$\Delta\boldsymbol{p}_{m q k}$进行编码，并且剩余的$MK$个通道被馈送到SoftMax算子以获得关注权重$A_{m q k}$。

可变形注意模块被设计用于将卷积特征映射作为关键元素进行处理。设$N_q$为查询元素的个数，当$M  K$较小时，可变形注意模块的复杂度为$O\left(2 N_{q} C^{2}+\min \left(H W C^{2}, N_{q} K C^{2}\right)\right)$(详见附录A.1)。当应用于DETR编码器时，当$N_q=HW$时，其复杂度为$O\left(H W C^{2}\right)$，其复杂度与空间大小呈线性关系。当将其应用于DETR解码器的交叉注意模块时，当$N_q=N$($N$为对象查询次数)时，复杂度为$O\left(N K C^{2}\right)$，与空间大小$HW$无关。

### Multi-scale Deformable Attention Module

大多数现代目标检测框架受益于多尺度特征地图(Liu等人，2020)。我们提出的可变形注意模块可以自然地扩展到多尺度特征地图。

设$\left\{\boldsymbol{x}^{l}\right\}_{l=1}^{L}$为输入的多比例尺特征地图，其中$\boldsymbol{x}^{l} \in \mathbb{R}^{C \times H_{l} \times W_{l}}$。设$\hat{\boldsymbol{p}}_{q} \in[0,1]^{2}$为每个查询元素q的参考点的归一化坐标，则多尺度可变形注意模块被应用为
$$
\operatorname{MSDeformAttn}\left(\boldsymbol{z}_{q}, \hat{\boldsymbol{p}}_{q},\left\{\boldsymbol{x}^{l}\right\}_{l=1}^{L}\right)=\sum_{m=1}^{M} \boldsymbol{W}_{m}\left[\sum_{l=1}^{L} \sum_{k=1}^{K} A_{m l q k} \cdot \boldsymbol{W}_{m}^{\prime} \boldsymbol{x}^{l}\left(\phi_{l}\left(\hat{\boldsymbol{p}}_{q}\right)+\Delta \boldsymbol{p}_{m l q k}\right)\right]
$$
其中$m$索引注意力头部，$l$索引输入特征级别，k索引采样点。$\Delta \boldsymbol{p}_{m l q k}$和$A_{m l q k}$分别表示第l个特征级别和第m个注意头中第k个采样点的采样偏移量和关注权重。标量注意权重$A_{m l q k}$被归一化为$\sum_{l=1}^{L} \sum_{k=1}^{K} A_{m l q k}=1$。这里，我们使用归一化坐标$\hat{\boldsymbol{p}}_{q} \in[0,1]^{2}$来表示尺度公式的清晰度，其中归一化坐标$(0，0)$和$(1，1)$分别表示图像的左上角和右下角。公式3中的函数$\phi_{l}\left(\hat{\boldsymbol{p}}_{q}\right)$将归一化坐标$\hat{\boldsymbol{p}}_{q}$重新缩放到$l$级的输入特征映射。多尺度可变形关注与之前的单尺度版本非常相似，不同之处在于它从多尺度特征地图中采样$LK$点，而不是从单尺度特征地图中采样K点。

当$L=1，K=1$，且$\boldsymbol{W}_{m}^{\prime} \in \mathbb{R}^{C_{v} \times C}$固定为单位矩阵时，所提出的注意模块将退化为可变形卷积(Dai等人，2017年)。可变形卷积是为单标度输入而设计的，只为每个注意力头部聚焦一个采样点。然而，我们的多尺度可变形注意关注来自多尺度输入的多个采样点。所提出的(多尺度)可变形注意模块也可以被视为变压器注意的有效变体，其中由可变形采样位置引入了预过滤机制。当采样点遍历所有可能的位置时，建议的注意模块相当于Transformer注意。

### Deformable Transformer Encoder

我们将DETR中处理特征映射的Transformer注意模块替换为所提出的多尺度可变形注意模块。编码器的输入和输出都是具有相同分辨率的多尺度特征地图。在编码器中，我们从Resnet(He  et al.，2016)中C3到C5阶段的输出特征图(经1×1卷积变换)中提取多尺度特征图$\left\{\boldsymbol{x}^{l}\right\}_{l=1}^{L-1}(L=4)$，其中CL的分辨率比输入图像低$2^l$。最低分辨率特征图$x_l$是在最后的C5级(记为C6)上通过3×3步长2卷积得到的。所有的多比例尺特征地图都是C=256通道。注意，FPN(Lin等人，2007a)中的自上而下结构没有使用，因为我们提出的多尺度可变形注意本身可以在多尺度特征地图之间交换信息。多比例尺要素地图的构建也在附录A.2中进行了说明。第5.2节中的实验表明，添加FPN不会提高性能。

在编码器中应用多尺度可变形注意模块时，输出的是与输入分辨率相同的多尺度特征地图。关键字和查询元素都是来自多比例尺要素地图的像素。对于每个查询像素，参考点就是其本身。为了识别每个查询像素所在的特征级别，除了位置嵌入之外，我们还向特征表示添加了比例级嵌入，表示为$\boldsymbol{e}_{l}$。与固定编码的位置嵌入不同，尺度级嵌入$\left\{\boldsymbol{e}_{l}\right\}_{l=1}^{L}$是随机初始化的，并与网络联合训练。

### Deformable Transformer Decoder

解码器中有交叉注意和自我注意模块。两种类型的注意模块的查询元素都是对象查询。在交叉注意模块中，对象查询从特征地图中提取特征，其中关键元素是编码器输出的特征地图。在自我注意模块中，object queries相互作用，其中关键要素是object queries。由于我们提出的可变形注意模块是为处理卷积特征映射而设计的，所以我们只将每个交叉注意模块替换为多尺度可变形注意模块，而保持自我注意模块不变。对于每个对象查询，通过后面跟随Sigmoid函数的可学习线性投影从其对象查询中预测点$\boldsymbol{p}_q$的2-D归一化坐标。

由于多尺度可变形注意模块提取参考点周围的图像特征，因此我们让检测头预测边界框为相对偏移量w.r.t。该参考点进一步降低了优化的难度。参考点被用作长方体中心的初始猜测。检测头预测相对偏移量W.r.t。参照点。有关详细信息，请查看附录A.3。这样，学习到的解码者注意力将与预测的包围盒具有很强的相关性，这也加速了训练收敛。

通过用DETR中的可变形注意模块替换变压器注意模块，我们建立了一种高效、快速的收敛检测系统，称为可变形DETR(见图1)。

## 4.2 Additional Improvements and Variants For Deformable DETR

可变形DETR由于其快速收敛以及计算和存储效率，为我们开发端到端对象探测器的各种变体打开了可能性。由于篇幅有限，我们在这里只介绍这些改进和变体的核心思想。实施细节见附录A.4。

### Iterative Bounding Box Refinement

这是受到光流估计(Teed&Den，2020)中发展的迭代精化的启发。为了提高检测性能，我们建立了一种简单有效的迭代包围盒求精机制。这里，每个解码层基于来自前一层的预测来细化边界框。

### Two-Stage Deformable DETR

在原始的DETR中，解码器中的对象查询与当前图像无关。受两阶段目标检测器的启发，我们探索了一种变形DETR的变体，作为第一阶段，用于生成区域建议。生成的区域建议将作为对象查询送入解码器进行进一步细化，形成一个两级可变形的DETR。

在第一阶段，为了实现高召回率，多尺度特征地图中的每个像素都将作为对象查询。然而，直接将对象查询设置为像素会给解码器中的自我注意模块带来不可接受的计算和存储开销，其复杂度随着查询次数的增加而呈二次曲线增长。为了避免这个问题，我们去掉了解码器，形成了一个只有编码器的可变形DETR来生成区域方案。在该方法中，每个像素被指定为一个对象查询，该查询直接预测一个边界框。得分最高的边界框被选为区域提案。在将区域建议提交到第二阶段之前，不应用NMS。

# 5. Experiment

### Dataset

我们在COCO  2017数据集上进行了实验(Lin等人，2014)。我们的模型在训练集上进行训练，并在VAL集和测试开发集上进行评估。

### Implementation Details

ImageNet(邓等人，2009年)预先训练的ResNet-50(他等人，2016年)被用作消融的主干。多比例特征地图的提取没有FPN(Lin等人，2007a)。默认情况下，为可变形关注设置M=8和K=4。可变形变压器编码器的参数在不同的特征级别之间共享。其他超参数设置和训练策略主要遵循DETR(Carion等人，2020)，除了将损失权重为2的Focal loss(Lin等人，2007b)用于边界框分类，以及对象查询数量从100增加到300。我们还报告了具有这些修改的DETR-DC5的性能，以进行公平的比较，表示为DETR-DC5+。默认情况下，模型训练50个时期，学习速率在40个时期衰减0.1倍。在DETR(Carion等人，2020年)之后，我们使用Adam优化器(Kingma&BA，2015年)训练我们的模型，基本学习率为2×10−4，β1=0.9，β2=0.999，权重衰减为10−4。用于预测对象查询参考点和采样偏移量的线性投影的学习率乘以0.1倍。运行时间在NVIDIA特斯拉V100图形处理器上进行了评估。

## 5.1 comparison with detr

如表1所示，与更快的R-CNN+FPN相比，DETR需要更多的训练周期才能收敛，并且在检测小目标时性能较差。与DETR相比，可变形DETR具有更好的性能(特别是在小目标上)，训练时间减少了10倍。详细的收敛曲线如图3所示。在迭代包围盒细化和两阶段范例的帮助下，我们的方法可以进一步提高检测精度。

我们提出的可变形DETR与速度更快的R-CNN+FPN和DETR-DC5具有相同的FLOPS。但运行速度比DETR-DC5快得多(1.6倍)，仅比更快的R-CNN+FPN慢25%。DETR-DC5的速度问题主要是由于Transformer注意中的大量内存访问造成的。我们提出的可变形注意可以缓解这个问题，但代价是无序的内存访问。因此，它仍然比传统的卷积稍微慢一些。

表1：COCO 2017 Val Set上可变形DETR与DETR的比较。DETR-DC5+表示具有焦点损失和300个对象查询的DETR-DC5。

图3：可变形DETR和DETR-DC5在COCO 2017  Val集合上的收敛曲线。对于可变形的DETR，我们通过改变学习速率降低的时期(AP分数跳跃的时候)来探索不同的训练时间表。

## 5.2 ablation study on deformable attention

表2列出了所提议的可变形注意模块的各种设计选择的消融。使用多尺度输入代替单尺度输入可以有效地提高1.7%AP的检测精度，特别是对于APS为2.9%的小目标。增加采样点K可以进一步提高0.9%的AP。使用多尺度可变形注意，允许不同尺度级别之间的信息交换，可以带来额外的1.5%的AP改善。由于已经采用了跨层的特征交换，所以添加FP网络不会提高性能。当不应用多尺度注意时，并且K=1，我们的(多尺度)可变形注意模块退化为可变形卷积，提供明显较低的精度。

表2：Coco  2017  ValSet上用于可变形注意的消融。“MS输入”表示使用多尺度输入。“MS注意”表示使用多尺度可变形注意。K是每个特征级别上每个注意力头部的采样点数量。

## 5.3 comparison with state-of-art methods

表3将提出的方法与其他最先进的方法进行了比较。表3中的模型都使用了迭代边界框求精和两阶段机制。使用ResNet-101和ResNeXt-101(Xie等人，2017)，我们的方法分别获得了48.7AP和49.0AP的无花哨效果。通过将ResNeXt-101与DCN(朱等人，2019b)一起使用，精度提高到50.1ap。在额外增加测试时间的情况下，该方法达到了52.3AP。

在COCO  2017测试开发集上将可变形DETR与最先进的方法进行比较。TTA表示测试时间的增加，包括水平翻转和多尺度测试。

# 6. Conclusion

可变形DETR是一种端到端的目标检测器，具有高效、快速收敛的特点。它使我们能够探索更有趣和更实用的端到端对象探测器的变体。可变形DETR的核心是(多尺度)可变形注意模块，它是处理图像特征图的一种有效的注意机制。我们希望我们的工作在探索端到端目标检测方面开辟了新的可能性。

# 7. appendix

## 7.1 complexity for deformable attention

假设查询元素的数量为Nq，在可变形注意模块中(见公式2)，用于计算采样坐标偏移量∆Pmqk和关注权重Amqk的复杂度为$O\left(3 N_{q} C M K\right)$。在给定采样坐标偏移量和关注权重的情况下，计算公式2的复杂度为$O\left(N_{q} C^{2}+N_{q} K C^{2}+5 N_{q} K C\right)$，其中$5 N_{q} K C$中的5因数是由于双线性内插和注意加权和所致。另一方面，我们也可以在抽样前计算$\boldsymbol{W}_{m}^{\prime} \boldsymbol{x}$，因为它与查询无关，所以计算公式2的复杂度为$O\left(N_{q} C^{2}+H W C^{2}+5 N_{q} K C\right)$。因此，变形注意的整体复杂度为$O\left(N_{q} C^{2}+\min \left(H W C^{2}, N_{q} K C^{2}\right)+5 N_{q} K C+3 N_{q} C M K\right)$。在我们的实验中，默认M=8，K≤4，C=2  5 6，即$5K+3M K<C$，其复杂度为$O\left(2 N_{q} C^{2}+\min \left(H W C^{2}, N_{q} K C^{2}\right)\right)$。

## 7.2 constructing multi-scale feature maps for deformable detr

如4.1节中讨论并在图4中所示，从Resnet(他等人，2016)中的阶段C3至C5的输出特征地图(通过1×1卷积变换)提取编码器{XL}L−1  l=1(L=4)的输入多尺度特征地图。最低分辨率特征图XL是在最后的C5级通过3×3步长2卷积得到的。注意，没有使用FPN(Lin等人，2007a)，因为我们提出的多尺度可变形注意本身可以在多尺度特征地图之间交换信息。

## 7.3 bounding box prediction in deformable detr

由于多尺度可变形注意模块提取参考点周围的图像特征，因此我们设计了检测头来预测包围盒的相对偏移量w.r.t。该参考点进一步降低了优化的难度。参考点被用作长方体中心的初始猜测。检测头预测相对偏移量W.r.t。参考点ˆpq=(ˆpqx，ˆpqy)，即ˆbq={σ？bqx+σ−1(ˆpqx)？，σ？bqy+σ−1(ˆpqy)？，σ(Bqw)，σ(Bqh)}，其中bq{x，y，w，h}∈R由检测头预测。σ和σ−1分别表示Sigmoid函数和逆Sigmoid函数。σ和σ−1的使用是为了确保ˆb是归一化坐标，如ˆbq∈[0，1]4。这样，学习的解码器注意力将与预测的包围盒具有很强的相关性，这也加快了训练收敛。

## 7.4 more implementation details

### iterative bounding box refinement

这里，每个解码层基于来自前一层的预测来细化边界框。假设存在D个解码器层(例如，D=6)，给定由第(dˆ)个解码器层预测的归一化边界盒BD−1q，第d个解码器层将该盒细化为



其中，在第d解码层预测d∈{1，2，...，D}，∆bdq{x，y，w，h}∈R。不同解码层的预测头不共享参数。初始框设置为ˆb0qx=ˆpqx、ˆb0qy=ˆpqy、ˆb0qw=0.1和ˆb0qh=0.1。系统对b0qw和b0qh的选择具有较强的鲁棒性。我们尝试将它们设置为0.05、0.1、0.2、0.5，并获得了类似的性能。为了稳定训练，类似于Ted&Den(2020)，梯度只通过∆bdq{x，y，w，h}反向传播，并在σ−1(ˆbd−1  q{x，y，w，h})处被阻挡。

在迭代边界盒精化中，对于第d个解码层，我们分别对从第(dˆ)个解码层预测的盒BD−1q的关键元素进行采样。对于第d解码层的交叉注意模块中的公式3，(ˆBD−1QX，ˆBD−1QY)用作新的参考点。采样偏移量∆pmlqk也由盒大小调制，如(∆pmlqkxˆBD−1QW，∆pmlqkyˆBD−1QH)。这样的修改使得采样位置与先前预测的框的中心和大小相关。

### two-stage deformable detr

在第一阶段，给定编码器的输出特征图，对每个像素施加一个检测头。检测头分别是用于包围盒回归的三层FFN和用于包围盒二值分类(即前景和背景)的线性投影。让I用二维归一化坐标$\hat{\boldsymbol{p}}_{i}=\left(\hat{p}_{i x}, \hat{p}_{i y}\right) \in[0,1]^{2}$索引来自要素级别li∈{1，2，...，L}的像素，其对应的边界框由下式预测
$$
\hat{\boldsymbol{b}}_{i}=\left\{\sigma\left(\Delta b_{i x}+\sigma^{-1}\left(\hat{p}_{i x}\right)\right), \sigma\left(\Delta b_{i y}+\sigma^{-1}\left(\hat{p}_{i y}\right)\right), \sigma\left(\Delta b_{i w}+\sigma^{-1}\left(2^{l_{i}-1} s\right)\right), \sigma\left(\Delta b_{i h}+\sigma^{-1}\left(2^{l_{i}-1} s\right)\right)\right\}
$$
在基本对象比例s设置为0.05时，$\Delta b_{i\{x, y, w, h\}} \in \mathbb{R}$由边界框回归分支预测。匈牙利在DETR中的损失用于训练探测头。

考虑到第一阶段预测的边界框，得分最高的边界框被选为区域建议。在第二阶段，将这些区域建议作为初始盒送入解码器进行迭代包围盒细化，其中对象查询的位置嵌入被设置为区域建议坐标的位置嵌入。

### initialization for multi-scale deformable attention

在实验中，注意头数设置为M=8。在多尺度可变形注意模块中，随机初始化W0m∈Rcv×C和Wm∈Rc×Cv。用于预测AMLQK和∆PMLQK的线性投影的权重参数被初始化为零。在初始化时，线性投影的偏置参数被初始化以使得amlqk=1lk和{∆p1lqk=(−k，−k)，∆p2lqk=(−k，0)，∆p3lqk=(−k，k)，∆p4lqk=(0，−k)，∆p5lqk=(0，k)，∆p6lqk=(k，−k)，∆p7lqk=(k，0)，∆p8lqk=(k，k)}(k∈{1，2，...k})。

对于迭代包围盒精化，解码器中用于∆PMLQK预测的初始化偏置参数进一步乘以12K，使得在初始化时的所有采样点都在从先前解码层预测的对应包围盒内。

## 7.5 what deformable detr looks at?

为了研究可变形DETR在最终检测结果中看什么，我们画出了最终预测中每一项相对于图像中每个像素的梯度范数(即物体中心的x/y坐标、物体边界框的宽度/高度、该物体的类别分数)，如图5所示。根据泰勒定理，梯度范数可以反映输出相对于像素扰动的变化程度，从而可以告诉我们模型对每一项的预测主要依赖于哪些像素。

可视化表明，可变形DETR查看对象的极值点以确定其边界框，这类似于DETR中的观察(Carion等人，2020)。更具体地说，对于x坐标和宽度，可变形DETR关注对象的左/右边界，而对于y坐标和高度，可变形DETR关注对象的上/下边界。同时，与DETR(Carion等人，2020)不同，我们的可变形DETR还会查看对象内部的像素来预测其类别。

图5：针对输入图像I中的每个像素的最终检测结果中的每一项的梯度范数(对象中心坐标(x，y)、对象边界框的宽度/高度w/h、该对象的类别分数c)。

## 7.6 visualization of multi-scale deformable attention

为了更好地理解学习的多尺度可变形注意模块，我们将编解码层最后一层的采样点和关注权重可视化，如图6所示。为了可读性，我们将不同分辨率的特征映射的采样点和关注权重组合成一幅图。

类似于DETR(Carion等人，2020)，实例已经在可变形DETR的编码器中分离。而在解码器中，我们的模型关注整个前景实例，而不是像DETR中观察到的那样只关注极点(Carion等人，2020)。结合图5中k∂c∂i  k的可视化，我们可以猜测其原因是我们的可变形判别器不仅需要极值点，而且还需要内点来确定对象类别。可视化实验还表明，所提出的多尺度可变形注意模块能够根据前景对象的不同尺度和形状自适应调整采样点和关注权重。

图6：多尺度可变形注意的可视化。为了可读性，我们从一张图片中不同分辨率的特征地图中提取采样点和关注度权重。每个采样点被标记为带孔的圆圈，其颜色表示其相应的关注度。参考点显示为绿色十字标记，也相当于编码器中的查询点。在解码器中，预测的边界框显示为一个绿色矩形，类别和置信度分数显示在其正上方。